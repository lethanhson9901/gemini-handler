# Gemini Handler ðŸš€

[![Giáº¥y phÃ©p: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
<!-- [![Tráº¡ng thÃ¡i Build](https://img.shields.io/travis/com/your-username/gemini-handler.svg)](https://travis-ci.com/your-username/gemini-handler) --> <!-- Cáº­p nháº­t liÃªn káº¿t CI/CD náº¿u cÃ³ -->

**ThÆ° viá»‡n Python máº¡nh máº½ giÃºp tÆ°Æ¡ng tÃ¡c hiá»‡u quáº£ vá»›i API Gemini cá»§a Google, tÃ­ch há»£p cÃ¡c tÃ­nh nÄƒng quáº£n lÃ½ API key thÃ´ng minh, chiáº¿n lÆ°á»£c xá»­ lÃ½ lá»—i linh hoáº¡t, kháº£ nÄƒng xá»­ lÃ½ file, táº¡o Ä‘áº§u ra cÃ³ cáº¥u trÃºc, há»— trá»£ proxy, vÃ  cung cáº¥p má»™t server tÆ°Æ¡ng thÃ­ch OpenAI.**

`gemini-handler` Ä‘Æ¡n giáº£n hÃ³a cÃ¡c tÃ¡c vá»¥ phá»• biáº¿n vÃ  tÄƒng cÆ°á»ng Ä‘á»™ bá»n cho cÃ¡c á»©ng dá»¥ng sá»­ dá»¥ng Gemini cá»§a báº¡n. ThÆ° viá»‡n quáº£n lÃ½ thÃ´ng minh nhiá»u API key Ä‘á»ƒ giáº£m thiá»ƒu giá»›i háº¡n tá»‘c Ä‘á»™ (rate limit), cung cáº¥p nhiá»u chiáº¿n lÆ°á»£c xá»­ lÃ½ lá»—i API, cÃ¡c phÆ°Æ¡ng thá»©c tiá»‡n lá»£i cho viá»‡c táº¡o vÄƒn báº£n, táº¡o embedding, thao tÃ¡c file, táº¡o dá»¯ liá»‡u cÃ³ cáº¥u trÃºc (JSON), vÃ  tÃ­ch há»£p dá»… dÃ ng vá»›i cÃ¡c há»‡ thá»‘ng khÃ¡c thÃ´ng qua server API hoáº·c adapter LiteLLM.

## âœ¨ TÃ­nh nÄƒng ná»•i báº­t

*   **ðŸ¤– Há»— trá»£ nhiá»u Model Gemini:** TÆ°Æ¡ng tÃ¡c vá»›i cÃ¡c model Gemini khÃ¡c nhau cho tÃ¡c vá»¥ vÄƒn báº£n, embedding vÃ  hÃ¬nh áº£nh (vision).
*   **ðŸ”‘ Quáº£n lÃ½ API Key NÃ¢ng cao:**
    *   Náº¡p key tá»« danh sÃ¡ch, biáº¿n mÃ´i trÆ°á»ng (`GEMINI_API_KEY`, `GEMINI_API_KEYS`) hoáº·c file cáº¥u hÃ¬nh YAML.
    *   Nhiá»u chiáº¿n lÆ°á»£c luÃ¢n chuyá»ƒn key (`ROUND_ROBIN`, `SEQUENTIAL`, `LEAST_USED`, `SMART_COOLDOWN`) Ä‘á»ƒ phÃ¢n phá»‘i táº£i vÃ  xá»­ lÃ½ rate limit mÆ°á»£t mÃ .
    *   Tá»± Ä‘á»™ng "lÃ m mÃ¡t" (cooldown) cho cÃ¡c key bá»‹ giá»›i háº¡n tá»‘c Ä‘á»™.
    *   Theo dÃµi thá»‘ng kÃª sá»­ dá»¥ng key (sá»‘ láº§n dÃ¹ng, lá»—i, thá»i gian bá»‹ giá»›i háº¡n).
*   **ðŸ”„ Táº¡o Ná»™i dung Bá»n bá»‰:**
    *   **Chiáº¿n lÆ°á»£c Retry (Thá»­ láº¡i):** Tá»± Ä‘á»™ng thá»­ láº¡i cÃ¡c yÃªu cáº§u tháº¥t báº¡i vá»›i Ä‘á»™ trá»… cÃ³ thá»ƒ cáº¥u hÃ¬nh.
    *   **Chiáº¿n lÆ°á»£c Fallback (Dá»± phÃ²ng):** Thá»­ táº¡o ná»™i dung vá»›i má»™t chuá»—i cÃ¡c model náº¿u model chÃ­nh tháº¥t báº¡i.
    *   **Chiáº¿n lÆ°á»£c Round Robin (LuÃ¢n phiÃªn):** Láº§n lÆ°á»£t thá»­ qua cÃ¡c model cÃ³ sáºµn.
*   **ðŸ“„ Äáº§u ra cÃ³ cáº¥u trÃºc (JSON):** Táº¡o ná»™i dung tuÃ¢n thá»§ nghiÃªm ngáº·t theo má»™t JSON schema Ä‘Æ°á»£c cung cáº¥p, tá»± Ä‘á»™ng phÃ¢n tÃ­ch cÃº phÃ¡p JSON tá»« pháº£n há»“i.
*   **ðŸ–¼ï¸ Xá»­ lÃ½ File:**
    *   Táº£i file cá»¥c bá»™ lÃªn API Gemini.
    *   Quáº£n lÃ½ cÃ¡c file Ä‘Ã£ táº£i lÃªn (láº¥y thÃ´ng tin, liá»‡t kÃª, xÃ³a).
    *   Tá»± Ä‘á»™ng chá» file chuyá»ƒn sang tráº¡ng thÃ¡i `ACTIVE` trÆ°á»›c khi sá»­ dá»¥ng.
    *   Táº£i hÃ ng loáº¡t file tá»« má»™t thÆ° má»¥c.
*   **ðŸ‘ï¸ Kháº£ nÄƒng Vision:**
    *   Táº¡o ná»™i dung dá»±a trÃªn hÃ¬nh áº£nh/file Ä‘Ã£ táº£i lÃªn (tá»± Ä‘á»™ng táº£i ná»™i dung file khi cáº§n).
    *   Táº¡o ná»™i dung trá»±c tiáº¿p tá»« file hÃ¬nh áº£nh cá»¥c bá»™ mÃ  khÃ´ng cáº§n táº£i lÃªn trÆ°á»›c.
*   **ðŸ’¡ Táº¡o Embedding:** Táº¡o embedding vÄƒn báº£n sá»­ dá»¥ng cÃ¡c model embedding Gemini Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh, há»— trá»£ `task_type`.
*   **âš™ï¸ TÃ¹y chá»‰nh Linh hoáº¡t:** Cáº¥u hÃ¬nh cÃ¡c tham sá»‘ táº¡o ná»™i dung (temperature, top_p, v.v.) vÃ  `system_instruction`.
*   **ðŸ“Š Pháº£n há»“i Chuáº©n hÃ³a:** Äá»‘i tÆ°á»£ng `ModelResponse` nháº¥t quÃ¡n cho má»i káº¿t quáº£, bao gá»“m tráº¡ng thÃ¡i thÃ nh cÃ´ng, vÄƒn báº£n/dá»¯ liá»‡u, lá»—i, thá»i gian xá»­ lÃ½, thÃ´ng tin key vÃ  file Ä‘Ã£ sá»­ dá»¥ng.
*   **ðŸŒ Há»— trá»£ Proxy:** Dá»… dÃ ng cáº¥u hÃ¬nh HTTP/HTTPS proxy thÃ´ng qua file cáº¥u hÃ¬nh, tham sá»‘ khá»Ÿi táº¡o hoáº·c biáº¿n mÃ´i trÆ°á»ng.
*   **ðŸ”Œ Server TÆ°Æ¡ng thÃ­ch OpenAI:** Cháº¡y má»™t server API (FastAPI) vá»›i cÃ¡c endpoint `/v1/chat/completions`, `/v1/embeddings`, `/v1/models` tÆ°Æ¡ng tá»± OpenAI, cho phÃ©p tÃ­ch há»£p dá»… dÃ ng vá»›i cÃ¡c cÃ´ng cá»¥ hiá»‡n cÃ³.
*   **ðŸš€ Giao diá»‡n DÃ²ng lá»‡nh (CLI):** Khá»Ÿi cháº¡y server API nhanh chÃ³ng tá»« terminal.
*   **ðŸ§© TÃ­ch há»£p LiteLLM:** Adapter tÃ­ch há»£p sáºµn Ä‘á»ƒ sá»­ dá»¥ng `gemini-handler` nhÆ° má»™t custom provider trong LiteLLM.

## ðŸ› ï¸ CÃ i Ä‘áº·t

Äáº£m báº£o báº¡n Ä‘Ã£ cÃ i Ä‘áº·t Python (>= 3.8).

1.  **CÃ i Ä‘áº·t thÆ° viá»‡n cáº§n thiáº¿t:**
    ```bash
    pip install google-generativeai PyYAML requests Pillow fastapi uvicorn litellm # ThÃªm litellm náº¿u cáº§n
    ```
    *   `google-generativeai`: ThÆ° viá»‡n chÃ­nh thá»©c cá»§a Google.
    *   `PyYAML`: Äá»ƒ Ä‘á»c file cáº¥u hÃ¬nh `.yaml`.
    *   `requests`: ÄÆ°á»£c dÃ¹ng ná»™i bá»™ (vÃ­ dá»¥: táº£i file tá»« URI).
    *   `Pillow`: Äá»ƒ xá»­ lÃ½ file hÃ¬nh áº£nh cá»¥c bá»™.
    *   `fastapi`, `uvicorn`: Äá»ƒ cháº¡y server API tÆ°Æ¡ng thÃ­ch OpenAI.
    *   `litellm`: Náº¿u báº¡n muá»‘n sá»­ dá»¥ng tÃ­ch há»£p LiteLLM.

2.  **CÃ i Ä‘áº·t `gemini-handler`:**
    *   **Tá»« mÃ£ nguá»“n (khuyáº¿n nghá»‹ hiá»‡n táº¡i):**
        ```bash
        git clone https://github.com/your-username/gemini-handler.git # Thay báº±ng Ä‘Æ°á»ng dáº«n repo thá»±c táº¿
        cd gemini-handler
        pip install .
        ```
    *   **(Khi Ä‘Æ°á»£c xuáº¥t báº£n)**
        ```bash
        # pip install gemini-handler
        ```

*(LÆ°u Ã½: Thay tháº¿ `your-username/gemini-handler` báº±ng Ä‘Æ°á»ng dáº«n kho lÆ°u trá»¯ thá»±c táº¿ cá»§a báº¡n)*

## ðŸ”‘ Cáº¥u hÃ¬nh: API Keys vÃ  Proxy

`gemini-handler` cáº§n cÃ¡c API key Google Gemini vÃ  cÃ³ thá»ƒ sá»­ dá»¥ng proxy.

### API Keys

ThÆ° viá»‡n sáº½ náº¡p key theo thá»© tá»± Æ°u tiÃªn sau:

1.  **Danh sÃ¡ch key truyá»n trá»±c tiáº¿p (Code):** Cung cáº¥p `api_keys=['key1', 'key2']` khi khá»Ÿi táº¡o `GeminiHandler`.
2.  **File Cáº¥u hÃ¬nh YAML:** Cung cáº¥p `config_path="duong/dan/toi/config.yaml"` khi khá»Ÿi táº¡o. File YAML cáº§n cÃ³ cáº¥u trÃºc (xem vÃ­ dá»¥ chi tiáº¿t bÃªn dÆ°á»›i).
3.  **Biáº¿n MÃ´i trÆ°á»ng (Nhiá»u Keys):** Äáº·t biáº¿n `GEMINI_API_KEYS` lÃ  má»™t chuá»—i cÃ¡c key, phÃ¢n tÃ¡ch bá»Ÿi dáº¥u pháº©y:
    ```bash
    export GEMINI_API_KEYS="API_KEY_CUA_BAN_1,API_KEY_CUA_BAN_2,API_KEY_CUA_BAN_3"
    ```
4.  **Biáº¿n MÃ´i trÆ°á»ng (Má»™t Key):** Äáº·t biáº¿n `GEMINI_API_KEY`:
    ```bash
    export GEMINI_API_KEY="API_KEY_DUY_NHAT_CUA_BAN"
    ```

Náº¿u khÃ´ng tÃ¬m tháº¥y key nÃ o qua cÃ¡c phÆ°Æ¡ng thá»©c trÃªn, thÆ° viá»‡n sáº½ bÃ¡o lá»—i `ValueError`.

### Proxy

Proxy cÃ³ thá»ƒ Ä‘Æ°á»£c cáº¥u hÃ¬nh qua:

1.  **File Cáº¥u hÃ¬nh YAML:** Xem má»¥c `proxy` trong vÃ­ dá»¥ YAML.
2.  **Tham sá»‘ `proxy_settings` (Code):** Cung cáº¥p dictionary `proxy_settings={'http': '...', 'https': '...'}` khi khá»Ÿi táº¡o `GeminiHandler`.
3.  **Biáº¿n MÃ´i trÆ°á»ng:** Äáº·t biáº¿n `HTTP_PROXY` vÃ  `HTTPS_PROXY`. Biáº¿n mÃ´i trÆ°á»ng sáº½ **ghi Ä‘Ã¨** cÃ i Ä‘áº·t tá»« file YAML hoáº·c tham sá»‘ `proxy_settings`.
    ```bash
    export HTTP_PROXY="http://user:pass@your-proxy.com:port"
    export HTTPS_PROXY="http://user:pass@your-proxy.com:port" # CÃ³ thá»ƒ giá»‘ng http
    ```

### Cáº¥u hÃ¬nh YAML Chi tiáº¿t (`config.yaml`)

Báº¡n cÃ³ thá»ƒ tÃ¹y chá»‰nh sÃ¢u hÆ¡n trong file `config.yaml`:

```yaml
# config.yaml vÃ­ dá»¥ Ä‘áº§y Ä‘á»§
gemini:
  # API Keys (báº¯t buá»™c)
  api_keys:
    - "AIzaSyBmWf7COPcA6r62lDUoZ3x0dp47iy7ttSk" # lethanhson99907
    - "AIzaSyAIsEdv54bT-UixRDnG5aoOGXbGaybPHMM" # lethanhson99908
    # - "..."

  # CÃ i Ä‘áº·t táº¡o ná»™i dung máº·c Ä‘á»‹nh (tÃ¹y chá»n)
  generation:
    temperature: 0.7          # Äá»™ sÃ¡ng táº¡o (0.0-1.0)
    top_p: 1.0                # NgÆ°á»¡ng xÃ¡c suáº¥t tÃ­ch lÅ©y
    top_k: 40                 # Sá»‘ token cÃ³ xÃ¡c suáº¥t cao nháº¥t Ä‘á»ƒ xem xÃ©t
    max_output_tokens: 8192   # Äá»™ dÃ i tá»‘i Ä‘a pháº£n há»“i (token)
    stop_sequences: []        # Danh sÃ¡ch chuá»—i dá»«ng táº¡o ná»™i dung
    response_mime_type: "text/plain" # Máº·c Ä‘á»‹nh lÃ  text, dÃ¹ng "application/json" cho structured output

  # Giá»›i háº¡n tá»‘c Ä‘á»™ máº·c Ä‘á»‹nh cá»§a key (tÃ¹y chá»n) - DÃ¹ng cho KeyRotationManager
  rate_limits:
    requests_per_minute: 60   # Sá»‘ request tá»‘i Ä‘a má»—i phÃºt trÃªn má»™t key
    reset_window: 60          # Thá»i gian (giÃ¢y) Ä‘á»ƒ bá»™ Ä‘áº¿m request cá»§a key reset vá» 0

  # Chiáº¿n lÆ°á»£c máº·c Ä‘á»‹nh (tÃ¹y chá»n) - CÃ³ thá»ƒ override khi khá»Ÿi táº¡o handler
  strategies:
    content: "round_robin"    # Chiáº¿n lÆ°á»£c táº¡o ná»™i dung ('round_robin', 'fallback', 'retry')
    key_rotation: "smart_cooldown" # Chiáº¿n lÆ°á»£c luÃ¢n chuyá»ƒn key ('sequential', 'round_robin', 'least_used', 'smart_cooldown')

  # CÃ i Ä‘áº·t thá»­ láº¡i máº·c Ä‘á»‹nh (tÃ¹y chá»n) - Chá»‰ Ã¡p dá»¥ng cho chiáº¿n lÆ°á»£c 'retry'
  retry:
    max_attempts: 3           # Sá»‘ láº§n thá»­ tá»‘i Ä‘a cho má»™t yÃªu cáº§u lá»—i
    delay: 30                 # Thá»i gian chá» (giÃ¢y) giá»¯a cÃ¡c láº§n thá»­

  # Model máº·c Ä‘á»‹nh (tÃ¹y chá»n)
  default_model: "gemini-2.0-flash" # Model dÃ¹ng khi khÃ´ng chá»‰ Ä‘á»‹nh
  system_instruction: null      # System prompt máº·c Ä‘á»‹nh

  # CÃ i Ä‘áº·t Embedding (tÃ¹y chá»n)
  embedding:
    default_model: "gemini-embedding-exp-03-07" # Model embedding máº·c Ä‘á»‹nh
    # CÃ¡c tÃ¹y chá»n khÃ¡c cÃ³ thá»ƒ thÃªm á»Ÿ Ä‘Ã¢y náº¿u cáº§n (vÃ­ dá»¥: task_type máº·c Ä‘á»‹nh)
    # dimensions: 768 # ThÃ´ng tin, khÃ´ng pháº£i cÃ i Ä‘áº·t trá»±c tiáº¿p
    # batch_size: 10 # ThÃ´ng tin, khÃ´ng pháº£i cÃ i Ä‘áº·t trá»±c tiáº¿p
    # task_types: ... # ThÃ´ng tin vá» cÃ¡c task type há»— trá»£

# CÃ i Ä‘áº·t Proxy (tÃ¹y chá»n)
proxy:
  http: "http://brd-customer-hl_8d87b67a-zone-residential_proxy1:eb0e1vrv5v2g@brd.superproxy.io:33335"
  https: "https://brd-customer-hl_8d87b67a-zone-residential_proxy1:eb0e1vrv5v2g@brd.superproxy.io:33335"

# CÃ i Ä‘áº·t Server API (tÃ¹y chá»n) - CÃ¡c giÃ¡ trá»‹ nÃ y cÃ³ thá»ƒ bá»‹ override bá»Ÿi CLI args
# server:
#   host: "0.0.0.0"
#   port: 8000
#   workers: 1 # Sá»‘ lÆ°á»£ng worker (náº¿u dÃ¹ng Gunicorn/Uvicorn nÃ¢ng cao)
#   log_level: "info"
# security: # CÃ i Ä‘áº·t báº£o máº­t cho server API
#   require_auth: false # YÃªu cáº§u API key Ä‘á»ƒ truy cáº­p server?
#   api_keys: [] # Danh sÃ¡ch cÃ¡c key há»£p lá»‡ náº¿u require_auth lÃ  true
```

## ðŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng `GeminiHandler`

### 1. Khá»Ÿi táº¡o CÆ¡ báº£n

```python
from gemini_handler import GeminiHandler, Strategy, KeyRotationStrategy, GenerationConfig

# Khá»Ÿi táº¡o Ä‘Æ¡n giáº£n nháº¥t (náº¡p key tá»« ENV hoáº·c config.yaml máº·c Ä‘á»‹nh náº¿u cÃ³)
try:
    handler_default = GeminiHandler()
except ValueError as e:
    print(f"Lá»—i: {e}. Vui lÃ²ng cáº¥u hÃ¬nh API keys.")
    # Xá»­ lÃ½ hoáº·c thoÃ¡t

# Khá»Ÿi táº¡o vá»›i danh sÃ¡ch key, chiáº¿n lÆ°á»£c vÃ  proxy cá»¥ thá»ƒ
api_keys = ["API_KEY_CUA_BAN_1", "API_KEY_CUA_BAN_2"]
proxy_config = {
    'http': 'http://user:pass@proxy.example.com:8080',
    'https': 'http://user:pass@proxy.example.com:8080'
}
handler_custom = GeminiHandler(
    api_keys=api_keys,
    content_strategy=Strategy.RETRY,
    key_strategy=KeyRotationStrategy.SMART_COOLDOWN,
    proxy_settings=proxy_config # Truyá»n cáº¥u hÃ¬nh proxy
)

# Khá»Ÿi táº¡o vá»›i file cáº¥u hÃ¬nh vÃ  system instruction
system_instruction = "Báº¡n lÃ  má»™t trá»£ lÃ½ AI há»¯u Ã­ch."
handler_with_config = GeminiHandler(
    config_path="config.yaml", # Äá»c cáº£ API keys vÃ  proxy tá»« file (náº¿u cÃ³)
    system_instruction=system_instruction
)

# Khá»Ÿi táº¡o vá»›i cáº¥u hÃ¬nh táº¡o ná»™i dung máº·c Ä‘á»‹nh khÃ¡c
custom_gen_config = GenerationConfig(temperature=0.5, max_output_tokens=1000)
handler_with_gen_config = GeminiHandler(
    api_keys=api_keys,
    generation_config=custom_gen_config
)

# GÃ¡n handler báº¡n muá»‘n sá»­ dá»¥ng cho biáº¿n `handler`
handler = handler_with_config # VÃ­ dá»¥: chá»n handler Ä‘á»c tá»« config
```

### 2. Táº¡o Ná»™i dung VÄƒn báº£n

```python
# Äá»‹nh nghÄ©a system prompt (náº¿u chÆ°a cÃ³ khi khá»Ÿi táº¡o)
# handler.system_instruction = "Báº¡n lÃ  má»™t chuyÃªn gia..." # CÃ³ thá»ƒ gÃ¡n láº¡i náº¿u cáº§n

prompt = "Giáº£i thÃ­ch vá» Ä‘iá»‡n toÃ¡n Ä‘Ã¡m mÃ¢y cho ngÆ°á»i má»›i báº¯t Ä‘áº§u."
response = handler.generate_content(prompt=prompt) # Sá»­ dá»¥ng system instruction Ä‘Ã£ gÃ¡n

if response['success']:
    print("VÄƒn báº£n Ä‘Æ°á»£c táº¡o:")
    print(response['text'])
    print(f"\nThá»i gian thá»±c hiá»‡n: {response['time']:.2f}s")
    print(f"Index cá»§a API Key Ä‘Ã£ dÃ¹ng: {response['api_key_index']}")
else:
    print(f"Lá»—i khi táº¡o ná»™i dung: {response['error']}")

# Táº¡o ná»™i dung vá»›i model cá»¥ thá»ƒ vÃ  láº¥y thá»‘ng kÃª key
response_detailed = handler.generate_content(
    prompt="Viáº¿t má»™t Ä‘oáº¡n vÄƒn ngáº¯n vá» lá»£i Ã­ch cá»§a viá»‡c Ä‘á»c sÃ¡ch.",
    model_name="gemini-1.5-flash", # Chá»‰ Ä‘á»‹nh model
    return_stats=True             # Láº¥y thá»‘ng kÃª sá»­ dá»¥ng key
)

if response_detailed['success']:
    print("\n" + response_detailed['text'])
    print("\nThá»‘ng kÃª Key:")
    import json
    print(json.dumps(response_detailed['key_stats'], indent=2))
else:
    print(f"Lá»—i: {response_detailed['error']}")
```

### 3. Táº¡o Dá»¯ liá»‡u cÃ³ Cáº¥u trÃºc (JSON)

```python
import json

# Äá»‹nh nghÄ©a cáº¥u trÃºc JSON mong muá»‘n (JSON Schema)
recipe_schema = {
    "type": "object",
    "properties": {
        "ten_mon_an": {"type": "string"},
        "nguyen_lieu": {"type": "array", "items": {"type": "string"}},
        "buoc_thuc_hien": {"type": "array", "items": {"type": "string"}},
        "thoi_gian_chuan_bi": {"type": "string", "description": "VÃ­ dá»¥: 15 phÃºt"},
        "thoi_gian_nau": {"type": "string", "description": "VÃ­ dá»¥: 30 phÃºt"}
    },
    "required": ["ten_mon_an", "nguyen_lieu", "buoc_thuc_hien"]
}

prompt = "Cho tÃ´i cÃ´ng thá»©c lÃ m mÃ³n phá»Ÿ bÃ² HÃ  Ná»™i Ä‘Æ¡n giáº£n táº¡i nhÃ ."

# Táº¡o dá»¯ liá»‡u cÃ³ cáº¥u trÃºc
# LÆ°u Ã½: generate_structured_content tá»± Ä‘á»™ng Ä‘áº·t response_mime_type="application/json"
result = handler.generate_structured_content(
    prompt=prompt,
    schema=recipe_schema,
    model_name="gemini-1.5-pro", # NÃªn dÃ¹ng model máº¡nh hÆ¡n cho JSON phá»©c táº¡p
    # temperature=0.2 # CÃ³ thá»ƒ override tham sá»‘ generation á»Ÿ Ä‘Ã¢y
)

if result['success'] and result['structured_data']:
    print("\nDá»¯ liá»‡u cáº¥u trÃºc Ä‘Æ°á»£c táº¡o:")
    recipe = result['structured_data']
    print(json.dumps(recipe, indent=2, ensure_ascii=False))
    # print(f"\nVÄƒn báº£n gá»‘c tá»« API: {result['text']}") # Há»¯u Ã­ch Ä‘á»ƒ debug náº¿u JSON parse lá»—i
elif result['success'] and not result['structured_data']:
     print(f"\nThÃ nh cÃ´ng nhÆ°ng khÃ´ng phÃ¢n tÃ­ch Ä‘Æ°á»£c JSON tá»« pháº£n há»“i:")
     print(result['text'])
     print(f"Lá»—i phÃ¢n tÃ­ch (náº¿u cÃ³): {result['error']}")
else:
    print(f"\nLá»—i khi táº¡o dá»¯ liá»‡u cáº¥u trÃºc: {result['error']}")

```

### 4. Táº¡o Embedding

```python
from gemini_handler import EmbeddingConfig # Import Ä‘á»ƒ dÃ¹ng háº±ng sá»‘ task_type

# handler = GeminiHandler(...) # Äáº£m báº£o báº¡n Ä‘Ã£ cÃ³ instance handler

texts_to_embed = [
    "CÃ¡ch máº¡ng cÃ´ng nghiá»‡p 4.0 lÃ  gÃ¬?",
    "Nhá»¯ng á»©ng dá»¥ng chÃ­nh cá»§a AI trong y táº¿.",
    "Python lÃ  ngÃ´n ngá»¯ láº­p trÃ¬nh phá»• biáº¿n.",
]

# Táº¡o embedding Ä‘Æ¡n giáº£n (sá»­ dá»¥ng model vÃ  task type máº·c Ä‘á»‹nh tá»« config)
response = handler.generate_embeddings(content=texts_to_embed)

if response['success']:
    print(f"\nÄÃ£ táº¡o {len(response['embeddings'])} embeddings.")
    # print(response['embeddings']) # Danh sÃ¡ch cÃ¡c vector embedding
    print(f"Vector Ä‘áº§u tiÃªn cÃ³ {len(response['embeddings'][0])} chiá»u.")
    print(f"Index cá»§a API Key Ä‘Ã£ dÃ¹ng: {response['api_key_index']}")
else:
    print(f"\nLá»—i khi táº¡o embeddings: {response['error']}")

# Táº¡o embedding vá»›i model vÃ  task_type cá»¥ thá»ƒ
response_specific = handler.generate_embeddings(
    content="TÃ¬m kiáº¿m tÃ i liá»‡u: thÆ° viá»‡n Python tá»‘t nháº¥t cho web development",
    model_name="gemini-embedding-exp-03-07", # Chá»‰ Ä‘á»‹nh model embedding
    task_type=EmbeddingConfig.RETRIEVAL_QUERY, # Chá»‰ Ä‘á»‹nh loáº¡i tÃ¡c vá»¥ lÃ  truy váº¥n
    return_stats=True
)

# CÃ¡c loáº¡i task_type kháº£ dá»¥ng trong EmbeddingConfig:
# SEMANTIC_SIMILARITY, CLASSIFICATION, CLUSTERING, RETRIEVAL_DOCUMENT,
# RETRIEVAL_QUERY, QUESTION_ANSWERING, FACT_VERIFICATION, CODE_RETRIEVAL_QUERY

if response_specific['success']:
    print("\nEmbedding cho truy váº¥n tÃ¬m kiáº¿m:")
    # print(response_specific['embeddings'])
    print("\nThá»‘ng kÃª Key:")
    print(json.dumps(response_specific['key_stats'], indent=2))
else:
    print(f"Lá»—i: {response_specific['error']}")
```

### 5. Thao tÃ¡c vá»›i File (Upload, Quáº£n lÃ½, Sá»­ dá»¥ng)

```python
from pathlib import Path
import time
import json # Äá»ƒ in Ä‘áº¹p

# handler = GeminiHandler(...) # Äáº£m báº£o báº¡n Ä‘Ã£ cÃ³ instance handler

# --- Táº£i File LÃªn ---
# file_path = "duong/dan/toi/hinh_anh_cua_ban.jpg" # Hoáº·c file PDF, video, audio... Ä‘Æ°á»£c há»— trá»£
file_path = Path("./cat_image.jpg") # VÃ­ dá»¥: táº¡o file áº£nh mÃ¨o Ä‘á»ƒ test
if not file_path.exists():
    # Táº¡o file áº£nh giáº£ náº¿u chÆ°a cÃ³ (cáº§n Pillow)
    try:
        from PIL import Image
        img = Image.new('RGB', (60, 30), color = 'red')
        img.save(file_path)
        print(f"ÄÃ£ táº¡o file áº£nh giáº£: {file_path}")
    except ImportError:
        print("Lá»—i: Cáº§n cÃ i Pillow Ä‘á»ƒ táº¡o áº£nh giáº£ (pip install Pillow)")
        # Xá»­ lÃ½ lá»—i hoáº·c thoÃ¡t
        exit()
    except Exception as e:
         print(f"Lá»—i khi táº¡o áº£nh giáº£: {e}")
         exit()

print(f"\nÄang táº£i lÃªn file: {file_path}...")
upload_result = handler.upload_file(file_path)

if upload_result['success']:
    uploaded_file_object = upload_result['file'] # Láº¥y Ä‘á»‘i tÆ°á»£ng file gá»‘c tá»« Google API
    uploaded_file_name = uploaded_file_object.name # Láº¥y tÃªn file dáº¡ng "files/..."
    print(f"File táº£i lÃªn thÃ nh cÃ´ng: {uploaded_file_name}")
    print(f"URI: {uploaded_file_object.uri}")
    print(f"Tráº¡ng thÃ¡i ban Ä‘áº§u: {uploaded_file_object.state.name}") # Truy cáº­p state.name

    # Chá» file Ä‘Æ°á»£c xá»­ lÃ½ (quan trá»ng!)
    print("Äang chá» file xá»­ lÃ½...")
    active_file_object = None
    for _ in range(6): # Thá»­ tá»‘i Ä‘a 6 láº§n (30 giÃ¢y)
        get_result = handler.get_file(uploaded_file_name)
        if get_result['success']:
            current_file_object = get_result['file']
            print(f"  Tráº¡ng thÃ¡i hiá»‡n táº¡i: {current_file_object.state.name}")
            if current_file_object.state.name == "ACTIVE":
                active_file_object = current_file_object
                break # ThoÃ¡t vÃ²ng láº·p khi Ä‘Ã£ ACTIVE
            elif current_file_object.state.name == "FAILED":
                 print("Lá»—i: File xá»­ lÃ½ tháº¥t báº¡i trÃªn server.")
                 break
        else:
            print(f"Lá»—i khi kiá»ƒm tra tráº¡ng thÃ¡i file: {get_result['error']}")
            # CÃ³ thá»ƒ break hoáº·c thá»­ láº¡i
        time.sleep(5) # Äá»£i 5 giÃ¢y giá»¯a cÃ¡c láº§n kiá»ƒm tra

    if active_file_object:
        print("File Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng.")

        # --- Láº¥y ThÃ´ng tin File (Ä‘Ã£ cÃ³ tá»« vÃ²ng láº·p trÃªn) ---
        print(f"\nThÃ´ng tin file: {active_file_object.name}")
        print(f"  Tráº¡ng thÃ¡i: {active_file_object.state.name}")
        print(f"  Loáº¡i MIME: {active_file_object.mime_type}")
        print(f"  KÃ­ch thÆ°á»›c: {active_file_object.size_bytes} bytes")

        # --- Táº¡o Ná»™i dung vá»›i File ÄÃ£ Táº£i LÃªn (VÄƒn báº£n) ---
        prompt_cho_file = "MÃ´ táº£ chi tiáº¿t ná»™i dung cá»§a hÃ¬nh áº£nh nÃ y."
        # Sá»­ dá»¥ng tÃªn file hoáº·c Ä‘á»‘i tÆ°á»£ng file Ä‘Ã£ láº¥y Ä‘Æ°á»£c
        file_gen_response = handler.generate_content_with_file(
            file=active_file_object, # Truyá»n Ä‘á»‘i tÆ°á»£ng file Ä‘Ã£ ACTIVE
            prompt=prompt_cho_file,
            model_name="gemini-1.5-pro" # Báº¯t buá»™c dÃ¹ng model vision
        )
        if file_gen_response['success']:
            print("\nNá»™i dung Ä‘Æ°á»£c táº¡o tá»« File:")
            print(file_gen_response['text'])
            print(f"ThÃ´ng tin file Ä‘Ã£ dÃ¹ng: {file_gen_response['file_info']}")
        else:
            print(f"\nLá»—i khi táº¡o ná»™i dung tá»« file: {file_gen_response['error']}")

        # --- Táº¡o Ná»™i dung vá»›i File ÄÃ£ Táº£i LÃªn (JSON) ---
        image_schema = {
            "type": "object",
            "properties": {
                "description": {"type": "string"},
                "objects_detected": {"type": "array", "items": {"type": "string"}},
                "dominant_colors": {"type": "array", "items": {"type": "string"}}
            },
            "required": ["description", "objects_detected"]
        }
        structured_file_gen_response = handler.generate_structured_content_with_file(
             file=active_file_object,
             prompt="PhÃ¢n tÃ­ch hÃ¬nh áº£nh nÃ y vÃ  trÃ­ch xuáº¥t thÃ´ng tin theo cáº¥u trÃºc yÃªu cáº§u.",
             schema=image_schema,
             model_name="gemini-1.5-pro" # DÃ¹ng model vision há»— trá»£ JSON
        )
        if structured_file_gen_response['success'] and structured_file_gen_response['structured_data']:
            print("\nDá»¯ liá»‡u cáº¥u trÃºc Ä‘Æ°á»£c táº¡o tá»« File:")
            print(json.dumps(structured_file_gen_response['structured_data'], indent=2, ensure_ascii=False))
        else:
            print(f"\nLá»—i khi táº¡o dá»¯ liá»‡u cáº¥u trÃºc tá»« file: {structured_file_gen_response['error']}")

        # --- XÃ³a File ---
        print(f"\nÄang xÃ³a file: {uploaded_file_name}...")
        delete_result = handler.delete_file(uploaded_file_name)
        if delete_result['success']:
            print(f"ÄÃ£ xÃ³a thÃ nh cÃ´ng file: {delete_result['deleted_file']}")
        else:
            print(f"Lá»—i khi xÃ³a file: {delete_result['error']}")

    else:
        print(f"File khÃ´ng chuyá»ƒn sang tráº¡ng thÃ¡i ACTIVE sau khi chá».")
        # CÃ¢n nháº¯c xÃ³a file náº¿u xá»­ lÃ½ lá»—i hoáº·c khÃ´ng thÃ nh cÃ´ng
        # handler.delete_file(uploaded_file_name)

else:
    print(f"Lá»—i khi táº£i file lÃªn: {upload_result['error']}")

# --- Liá»‡t kÃª Files ---
print("\nÄang liá»‡t kÃª cÃ¡c file...")
list_result = handler.list_files(page_size=5) # Láº¥y tá»‘i Ä‘a 5 file má»—i trang
if list_result['success']:
    print("Danh sÃ¡ch Files:")
    if list_result['files']:
        for f in list_result['files']:
             # Truy cáº­p state qua .name
             print(f" - {f['name']} ({f['mime_type']}, Tráº¡ng thÃ¡i: {f['state'].name if f.get('state') else 'N/A'})")
        # if list_result['next_page_token']: # FileHandler hiá»‡n táº¡i khÃ´ng tráº£ token dá»… dÃ ng
        #     print(f"CÃ²n trang tiáº¿p theo (next_page_token): {list_result['next_page_token']}")
    else:
        print("  (KhÃ´ng cÃ³ file nÃ o)")
else:
    print(f"Lá»—i khi liá»‡t kÃª files: {list_result['error']}")

# --- Táº£i HÃ ng Loáº¡t (Batch Upload) ---
# Táº¡o thÆ° má»¥c vÃ  file giáº£ Ä‘á»ƒ vÃ­ dá»¥
batch_dir = Path("temp_upload_dir")
batch_dir.mkdir(exist_ok=True)
(batch_dir / "tai_lieu_1.txt").write_text("Ná»™i dung file text 1.", encoding='utf-8')
(batch_dir / "hinh_anh_doc.png").touch() # Táº¡o file rá»—ng
(batch_dir / "script_util.py").write_text("print('Hello Utility')", encoding='utf-8')

print("\nÄang táº£i lÃªn hÃ ng loáº¡t tá»« thÆ° má»¥c 'temp_upload_dir'...")
batch_result = handler.batch_upload_files(
    directory_path=batch_dir,
    file_extensions=['.txt', '.png'] # Chá»‰ táº£i file cÃ³ Ä‘uÃ´i .txt hoáº·c .png
)
if batch_result['success']:
    print(f"ÄÃ£ táº£i lÃªn thÃ nh cÃ´ng {batch_result['count']} files:")
    uploaded_batch_files = []
    for f_info in batch_result['files']:
        print(f" - {f_info['name']} ({f_info['mime_type']})")
        uploaded_batch_files.append(f_info['name']) # LÆ°u tÃªn Ä‘á»ƒ xÃ³a sau

    # Dá»n dáº¹p cÃ¡c file vá»«a táº£i lÃªn (vÃ­ dá»¥)
    print("\nÄang dá»n dáº¹p cÃ¡c file vá»«a batch upload...")
    # for file_name_to_delete in uploaded_batch_files:
    #     try:
    #         # Chá» file ACTIVE trÆ°á»›c khi xÃ³a náº¿u cáº§n dÃ¹ng ngay
    #         # Hoáº·c xÃ³a trá»±c tiáº¿p náº¿u khÃ´ng cáº§n dÃ¹ng
    #         # Cáº§n vÃ²ng láº·p chá» tÆ°Æ¡ng tá»± nhÆ° upload Ä‘Æ¡n láº» náº¿u muá»‘n Ä‘áº£m báº£o xÃ³a Ä‘Æ°á»£c
    #         del_res = handler.delete_file(file_name_to_delete)
    #         if del_res['success']:
    #             print(f"  ÄÃ£ xÃ³a {file_name_to_delete}")
    #         else:
    #              print(f"  Lá»—i xÃ³a {file_name_to_delete}: {del_res['error']}")
    #     except Exception as e_del:
    #         print(f"  Lá»—i ngoáº¡i lá»‡ khi xÃ³a {file_name_to_delete}: {e_del}")
else:
    print(f"Lá»—i trong quÃ¡ trÃ¬nh táº£i hÃ ng loáº¡t: {batch_result['error']}")

# Dá»n dáº¹p thÆ° má»¥c táº¡m
import shutil
try:
    shutil.rmtree(batch_dir)
    print(f"\nÄÃ£ xÃ³a thÆ° má»¥c táº¡m '{batch_dir}'.")
except OSError as e:
    print(f"Lá»—i khi xÃ³a thÆ° má»¥c táº¡m: {e}")

# Dá»n dáº¹p file áº£nh test ban Ä‘áº§u
try:
    file_path.unlink(missing_ok=True)
    print(f"ÄÃ£ xÃ³a file áº£nh test '{file_path}'.")
except OSError as e:
    print(f"Lá»—i khi xÃ³a file áº£nh test: {e}")
```

### 6. Táº¡o Ná»™i dung vá»›i File Cá»¥c bá»™ (KhÃ´ng cáº§n Upload)

Há»¯u Ã­ch cho viá»‡c phÃ¢n tÃ­ch nhanh hÃ¬nh áº£nh cá»¥c bá»™ mÃ  khÃ´ng cáº§n lÆ°u trá»¯ chÃºng qua File API.

```python
from pathlib import Path
import json

# handler = GeminiHandler(...) # Äáº£m báº£o báº¡n Ä‘Ã£ cÃ³ instance handler

local_image_path = Path("./local_image.jpeg")
if not local_image_path.exists():
    # Táº¡o file áº£nh giáº£ náº¿u chÆ°a cÃ³
    try:
        from PIL import Image
        img = Image.new('RGB', (80, 40), color = 'blue')
        img.save(local_image_path)
        print(f"ÄÃ£ táº¡o file áº£nh giáº£ cá»¥c bá»™: {local_image_path}")
    except ImportError:
        print("Lá»—i: Cáº§n cÃ i Pillow Ä‘á»ƒ táº¡o áº£nh giáº£ (pip install Pillow)")
        exit()
    except Exception as e:
         print(f"Lá»—i khi táº¡o áº£nh giáº£: {e}")
         exit()

# --- Táº¡o VÄƒn báº£n tá»« áº¢nh Cá»¥c bá»™ ---
print(f"\nÄang táº¡o ná»™i dung tá»« file cá»¥c bá»™: {local_image_path}...")
local_gen_response = handler.generate_with_local_file(
    file_path=local_image_path,
    prompt="CÃ³ nhá»¯ng Ä‘á»‘i tÆ°á»£ng nÃ o trong bá»©c áº£nh nÃ y?",
    model_name="gemini-1.5-pro" # Báº¯t buá»™c dÃ¹ng model vision
)

if local_gen_response['success']:
    print("\nNá»™i dung Ä‘Æ°á»£c táº¡o tá»« File Cá»¥c bá»™:")
    print(local_gen_response['text'])
    print(f"ThÃ´ng tin file: {local_gen_response['file_info']}")
else:
    print(f"\nLá»—i khi táº¡o ná»™i dung tá»« file cá»¥c bá»™: {local_gen_response['error']}")

# --- Táº¡o JSON tá»« áº¢nh Cá»¥c bá»™ ---
local_structured_response = handler.generate_with_local_file(
    file_path=local_image_path,
    prompt="MÃ´ táº£ chá»§ thá»ƒ chÃ­nh vÃ  mÃ u sáº¯c chá»§ Ä‘áº¡o cá»§a bá»©c áº£nh nÃ y.",
    schema={ # VÃ­ dá»¥ schema
        "type": "object",
        "properties": {
            "chu_the": {"type": "string"},
            "mau_sac": {"type": "array", "items": {"type": "string"}}
        },
        "required": ["chu_the", "mau_sac"]
    },
    model_name="gemini-1.5-pro" # DÃ¹ng model vision há»— trá»£ JSON
)

if local_structured_response['success'] and local_structured_response['structured_data']:
    print("\nDá»¯ liá»‡u cáº¥u trÃºc Ä‘Æ°á»£c táº¡o tá»« File Cá»¥c bá»™:")
    print(json.dumps(local_structured_response['structured_data'], indent=2, ensure_ascii=False))
else:
    print(f"\nLá»—i khi táº¡o dá»¯ liá»‡u cáº¥u trÃºc tá»« file cá»¥c bá»™: {local_structured_response['error']}")

# Dá»n dáº¹p file áº£nh test cá»¥c bá»™
try:
    local_image_path.unlink(missing_ok=True)
    print(f"\nÄÃ£ xÃ³a file áº£nh cá»¥c bá»™ test '{local_image_path}'.")
except OSError as e:
    print(f"Lá»—i khi xÃ³a file áº£nh cá»¥c bá»™ test: {e}")

```

## ðŸš€ Cháº¡y Server TÆ°Æ¡ng thÃ­ch OpenAI

ThÆ° viá»‡n bao gá»“m má»™t server API dá»±a trÃªn FastAPI, cung cáº¥p cÃ¡c endpoint tÆ°Æ¡ng tá»± OpenAI, cho phÃ©p tÃ­ch há»£p `gemini-handler` vá»›i cÃ¡c cÃ´ng cá»¥ vÃ  á»©ng dá»¥ng hiá»‡n cÃ³ há»— trá»£ API cá»§a OpenAI.

### Cháº¡y Server tá»« DÃ²ng lá»‡nh (CLI)

CÃ¡ch dá»… nháº¥t Ä‘á»ƒ khá»Ÿi cháº¡y server lÃ  sá»­ dá»¥ng CLI tÃ­ch há»£p:

```bash
python -m gemini_handler.cli --config config.yaml --port 8000
```

**CÃ¡c tÃ¹y chá»n CLI:**

*   `--host`: Äá»‹a chá»‰ IP Ä‘á»ƒ server láº¯ng nghe (máº·c Ä‘á»‹nh: `0.0.0.0`).
*   `--port`: Cá»•ng Ä‘á»ƒ server láº¯ng nghe (máº·c Ä‘á»‹nh: `8000`).
*   `--keys`: Danh sÃ¡ch API key Gemini, phÃ¢n tÃ¡ch bá»Ÿi dáº¥u pháº©y (vÃ­ dá»¥: `"key1,key2"`). **Æ¯u tiÃªn cao nháº¥t**, sáº½ ghi Ä‘Ã¨ key tá»« config hoáº·c ENV.
*   `--config`: ÄÆ°á»ng dáº«n Ä‘áº¿n file cáº¥u hÃ¬nh YAML (máº·c Ä‘á»‹nh: `config.yaml`). Server sáº½ Ä‘á»c cÃ¡c cÃ i Ä‘áº·t nhÆ° `api_keys`, `strategies`, `rate_limits`, `proxy`, `generation` tá»« file nÃ y (náº¿u khÃ´ng bá»‹ override bá»Ÿi CLI args hoáº·c ENV).

Server sáº½ tá»± Ä‘á»™ng sá»­ dá»¥ng cÃ¡c chiáº¿n lÆ°á»£c, quáº£n lÃ½ key, vÃ  há»— trá»£ proxy Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh thÃ´ng qua file YAML hoáº·c cÃ¡c giÃ¡ trá»‹ máº·c Ä‘á»‹nh.

### CÃ¡c Endpoints cá»§a Server

Server cung cáº¥p cÃ¡c endpoint sau, tÆ°Æ¡ng thÃ­ch vá»›i Ä‘á»‹nh dáº¡ng cá»§a OpenAI API v1:

*   **`GET /v1/models`**: Liá»‡t kÃª danh sÃ¡ch cÃ¡c model Gemini Ä‘Æ°á»£c há»— trá»£ bá»Ÿi server (vÃ­ dá»¥: `gemini-1.5-pro`, `gemini-embedding-exp-03-07`).
*   **`POST /v1/chat/completions`**: Táº¡o pháº£n há»“i chat. Nháº­n vÃ o request body tÆ°Æ¡ng tá»± OpenAI (vá»›i `model`, `messages`, `temperature`, `max_tokens`, `stream` (hiá»‡n chÆ°a há»— trá»£), `response_format`={ "type": "json_object" }, v.v.). Server sáº½ chuyá»ƒn Ä‘á»•i `messages` thÃ nh prompt vÃ  gá»i phÆ°Æ¡ng thá»©c `generate_content` hoáº·c `generate_structured_content` cá»§a `GeminiHandler`.
*   **`POST /v1/embeddings`**: Táº¡o embeddings. Nháº­n vÃ o request body tÆ°Æ¡ng tá»± OpenAI (vá»›i `model`, `input`). Server sáº½ gá»i phÆ°Æ¡ng thá»©c `generate_embeddings` cá»§a `GeminiHandler`.
*   **`GET /health`**: Endpoint kiá»ƒm tra sá»©c khá»e Ä‘Æ¡n giáº£n, tráº£ vá» `{"status": "ok"}`.

### VÃ­ dá»¥ Sá»­ dá»¥ng Server (vá»›i `curl`)

```bash
# 1. Láº¥y danh sÃ¡ch models
curl http://localhost:8000/v1/models

# 2. Táº¡o chat completion
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-1.5-flash",
    "messages": [
      {"role": "system", "content": "Báº¡n lÃ  trá»£ lÃ½."},
      {"role": "user", "content": "Viáº¿t cÃ¢u chÃ o buá»•i sÃ¡ng."}
    ],
    "temperature": 0.7,
    "max_tokens": 50
  }'

# 3. Táº¡o chat completion yÃªu cáº§u JSON output
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-1.5-pro",
    "messages": [
      {"role": "user", "content": "Cho tÃ´i thÃ´ng tin vá» Paris dÆ°á»›i dáº¡ng JSON vá»›i key lÃ  city vÃ  country."}
    ],
    "response_format": { "type": "json_object" }
  }'


# 4. Táº¡o embeddings
curl http://localhost:8000/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-embedding-exp-03-07",
    "input": "VÄƒn báº£n cáº§n táº¡o embedding"
  }'

# 5. Kiá»ƒm tra health
curl http://localhost:8000/health
```

## ðŸ§© TÃ­ch há»£p vá»›i LiteLLM

Sá»­ dá»¥ng `LiteLLMGeminiAdapter` Ä‘á»ƒ tÃ­ch há»£p `gemini-handler` nhÆ° má»™t custom provider trong LiteLLM. Äiá»u nÃ y cho phÃ©p báº¡n táº­n dá»¥ng cÃ¡c tÃ­nh nÄƒng quáº£n lÃ½ key vÃ  chiáº¿n lÆ°á»£c cá»§a `gemini-handler` trong mÃ´i trÆ°á»ng LiteLLM.

### Cáº¥u hÃ¬nh LiteLLM

ÄÄƒng kÃ½ provider tÃ¹y chá»‰nh trong code cá»§a báº¡n:

```python
import litellm
import os

# Äáº£m báº£o gemini_handler Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t
# ÄÄƒng kÃ½ provider, trá» Ä‘áº¿n adapter class
litellm.register_provider(
    "custom_gemini",
    import_string="gemini_handler.LiteLLMGeminiAdapter" # ÄÆ°á»ng dáº«n import chÃ­nh xÃ¡c
)

# ---- Cáº¥u hÃ¬nh API Keys cho Adapter ----
# Æ¯u tiÃªn 1: Äáº·t biáº¿n mÃ´i trÆ°á»ng LiteLLM_GEMINI_API_KEY (LiteLLM khuyáº¿n nghá»‹)
# os.environ["LITELLM_GEMINI_API_KEY"] = "key_cua_ban"

# Æ¯u tiÃªn 2: Äáº·t biáº¿n mÃ´i trÆ°á»ng GEMINI_API_KEYS (phÃ¢n tÃ¡ch bá»Ÿi dáº¥u pháº©y)
os.environ["GEMINI_API_KEYS"] = "AIzaSyBmWf7COPcA6r62lDUoZ3x0dp47iy7ttSk,AIzaSyAIsEdv54bT-UixRDnG5aoOGXbGaybPHMM"

# Æ¯u tiÃªn 3: Äáº·t biáº¿n mÃ´i trÆ°á»ng GEMINI_API_KEY
# os.environ["GEMINI_API_KEY"] = "key_cua_ban"

# Æ¯u tiÃªn 4: Truyá»n trá»±c tiáº¿p khi gá»i (Ã­t khuyáº¿n khÃ­ch hÆ¡n cho adapter dÃ¹ng chung)
# api_key_param = "key_cua_ban"

# LÆ°u Ã½: Adapter sáº½ chá»‰ khá»Ÿi táº¡o handler má»™t láº§n vÃ  tÃ¡i sá»­ dá»¥ng.
# NÃ³ sáº½ tÃ¬m key theo thá»© tá»±: LITELLM_GEMINI_API_KEY -> GEMINI_API_KEYS -> GEMINI_API_KEY.
# Náº¿u báº¡n truyá»n api_key khi gá»i litellm.completion, nÃ³ sáº½ Ä‘Æ°á»£c Æ°u tiÃªn cho *láº§n gá»i Ä‘Ã³*,
# nhÆ°ng khÃ´ng thay Ä‘á»•i handler dÃ¹ng chung trá»« khi handler chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o.
```

### Sá»­ dá»¥ng vá»›i LiteLLM

Gá»i cÃ¡c hÃ m cá»§a LiteLLM, chá»‰ Ä‘á»‹nh model vá»›i tiá»n tá»‘ `custom_gemini/`:

```python
# --- Chat Completion ---
try:
    response = litellm.completion(
        model="custom_gemini/gemini-1.5-pro", # Sá»­ dá»¥ng tiá»n tá»‘ Ä‘Ã£ Ä‘Äƒng kÃ½
        messages=[
            {"role": "user", "content": "Hello, how are you?"}
        ],
        temperature=0.5
        # api_key=api_key_param # Chá»‰ truyá»n náº¿u muá»‘n override cho láº§n gá»i nÃ y
    )
    print("\nLiteLLM Completion Response:")
    print(response)

    # Láº¥y ná»™i dung tráº£ vá»
    if response and response.choices and response.choices[0].message:
         print("\nContent:", response.choices[0].message.content)

except Exception as e:
    print(f"\nLá»—i LiteLLM Completion: {e}")


# --- Embedding ---
try:
    embedding_response = litellm.embedding(
        model="custom_gemini/gemini-embedding-exp-03-07", # Sá»­ dá»¥ng tiá»n tá»‘
        input=["Your text to embed here", "Another text"]
        # api_key=api_key_param
    )
    print("\nLiteLLM Embedding Response:")
    # print(embedding_response)
    if embedding_response and embedding_response.data:
        print(f"Generated {len(embedding_response.data)} embeddings.")
        print(f"First embedding dimensions: {len(embedding_response.data[0].embedding)}")

except Exception as e:
    print(f"\nLá»—i LiteLLM Embedding: {e}")

```

Adapter sáº½ tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i Ä‘á»‹nh dáº¡ng request/response giá»¯a LiteLLM vÃ  `GeminiHandler`.

## ðŸŽ¯ CÃ¡c chiáº¿n lÆ°á»£c

### Chiáº¿n lÆ°á»£c táº¡o ná»™i dung (`content_strategy`)

| Chiáº¿n lÆ°á»£c         | MÃ´ táº£                                                                   | Khi nÃ o sá»­ dá»¥ng                                  |
| :----------------- | :---------------------------------------------------------------------- | :----------------------------------------------- |
| **`ROUND_ROBIN`**  | Sá»­ dá»¥ng láº§n lÆ°á»£t cÃ¡c model trong danh sÃ¡ch `models` theo vÃ²ng trÃ²n.       | Khi muá»‘n phÃ¢n tÃ¡n táº£i Ä‘á»u cho cÃ¡c model.         |
| **`FALLBACK`**     | Thá»­ model chá»‰ Ä‘á»‹nh (hoáº·c model Ä‘áº§u tiÃªn), náº¿u lá»—i thÃ¬ thá»­ model tiáº¿p theo. | Khi cáº§n Ä‘á»™ tin cáº­y cao, Æ°u tiÃªn model tá»‘t nháº¥t. |
| **`RETRY`**        | Thá»­ láº¡i cÃ¹ng má»™t model nhiá»u láº§n (theo `max_attempts`) khi gáº·p lá»—i.        | Khi muá»‘n nháº¥t quÃ¡n vá» model sá»­ dá»¥ng cho 1 prompt. |

### Chiáº¿n lÆ°á»£c luÃ¢n chuyá»ƒn API key (`key_strategy`)

| Chiáº¿n lÆ°á»£c             | MÃ´ táº£                                                                                                | Khi nÃ o sá»­ dá»¥ng                                          |
| :--------------------- | :--------------------------------------------------------------------------------------------------- | :------------------------------------------------------- |
| **`SEQUENTIAL`**       | Sá»­ dá»¥ng cÃ¡c key theo thá»© tá»± trong danh sÃ¡ch, quay láº¡i Ä‘áº§u khi háº¿t.                                    | ÄÆ¡n giáº£n, khi muá»‘n Æ°u tiÃªn má»™t sá»‘ key nháº¥t Ä‘á»‹nh.         |
| **`ROUND_ROBIN`**      | Sá»­ dá»¥ng cÃ¡c key láº§n lÆ°á»£t theo vÃ²ng trÃ²n, bá» qua key bá»‹ rate limit hoáº·c khÃ´ng kháº£ dá»¥ng.                 | Khi muá»‘n phÃ¢n bá»• Ä‘á»u cÃ¡c request, dá»… dá»± Ä‘oÃ¡n.          |
| **`LEAST_USED`**       | Æ¯u tiÃªn key cÃ³ sá»‘ láº§n sá»­ dá»¥ng Ã­t nháº¥t trong khoáº£ng `reset_window` vÃ  Ä‘ang kháº£ dá»¥ng.                   | Khi cáº§n cÃ¢n báº±ng táº£i thá»±c táº¿ giá»¯a cÃ¡c key.               |
| **`SMART_COOLDOWN`**   | Tá»± Ä‘á»™ng "lÃ m mÃ¡t" key bá»‹ rate limit, Æ°u tiÃªn key Ã­t lá»—i vÃ  Ä‘Ã£ nghá»‰ lÃ¢u nháº¥t trong sá»‘ key kháº£ dá»¥ng.   | Khi cáº§n kháº£ nÄƒng tá»± phá»¥c há»“i cao, tá»‘i Æ°u khi key bá»‹ limit. |

## ðŸ’¡ Sá»­ dá»¥ng nÃ¢ng cao

### TÃ¹y chá»‰nh chiáº¿n lÆ°á»£c khi khá»Ÿi táº¡o

```python
from gemini_handler import GeminiHandler, Strategy, KeyRotationStrategy, GenerationConfig

# Khá»Ÿi táº¡o vá»›i chiáº¿n lÆ°á»£c tÃ¹y chá»‰nh vÃ  override generation config
handler_advanced = GeminiHandler(
    config_path="config.yaml", # Náº¡p keys, proxy tá»« file
    content_strategy=Strategy.FALLBACK,         # DÃ¹ng chiáº¿n lÆ°á»£c dá»± phÃ²ng
    key_strategy=KeyRotationStrategy.LEAST_USED, # DÃ¹ng key Ã­t sá»­ dá»¥ng nháº¥t
    generation_config=GenerationConfig(temperature=0.8, top_k=50) # Override generation
)
# Sá»­ dá»¥ng handler_advanced cho cÃ¡c tÃ¡c vá»¥ tiáº¿p theo
```

### Theo dÃµi hiá»‡u suáº¥t Request

```python
import json
import time

# Táº¡o ná»™i dung vÃ  yÃªu cáº§u tráº£ vá» thá»‘ng kÃª
response_perf = handler.generate_content(
    prompt="Viáº¿t má»™t bÃ i phÃ¢n tÃ­ch vá» xu hÆ°á»›ng AI nÄƒm 2024",
    return_stats=True # Quan trá»ng: Ä‘áº·t lÃ  True
)

if response_perf['success']:
    print(response_perf['text'])
    print("-" * 20)
    print(f"Thá»i gian thá»±c hiá»‡n: {response_perf['time']:.2f} giÃ¢y")
    print(f"Model Ä‘Ã£ sá»­ dá»¥ng: {response_perf['model']}")
    print(f"Index Key Ä‘Ã£ sá»­ dá»¥ng: {response_perf['api_key_index']}")
    print(f"Sá»‘ láº§n thá»­ (náº¿u dÃ¹ng Retry): {response_perf.get('attempts', 1)}") # attempts chá»‰ cÃ³ Ã½ nghÄ©a vá»›i Retry
    print("\nThá»‘ng kÃª Key:")
    print(json.dumps(response_perf['key_stats'], indent=2))

else:
    print(f"Lá»—i: {response_perf['error']}")
```

### GiÃ¡m sÃ¡t Tá»•ng thá»ƒ Sá»­ dá»¥ng API key

```python
import json
import time
import datetime

# Láº¥y thá»‘ng kÃª sá»­ dá»¥ng cho táº¥t cáº£ cÃ¡c key
all_key_stats = handler.get_key_stats()

print("\nThá»‘ng kÃª Tá»•ng thá»ƒ Sá»­ dá»¥ng Key:")
print(json.dumps(all_key_stats, indent=2))

# Láº¥y thá»‘ng kÃª cho má»™t key cá»¥ thá»ƒ (vÃ­ dá»¥: key thá»© 2 - index 1)
try:
    key_1_stats = handler.get_key_stats(key_index=1)
    print("\nThá»‘ng kÃª cho Key Index 1:")
    print(json.dumps(key_1_stats, indent=2))
except (IndexError, ValueError) as e:
    print(f"\nKhÃ´ng thá»ƒ láº¥y thá»‘ng kÃª cho key index 1: {e}")

# Hiá»ƒn thá»‹ thÃ´ng tin tá»«ng key má»™t cÃ¡ch dá»… Ä‘á»c
print("\nChi tiáº¿t tá»«ng Key:")
for key_idx, stats in all_key_stats.items():
    print(f"  Key {key_idx}:")
    print(f"    Sá»‘ láº§n sá»­ dá»¥ng (trong window): {stats['uses']}")
    last_used_time_str = "ChÆ°a sá»­ dá»¥ng"
    if stats['last_used'] > 0:
        last_used_time_str = datetime.datetime.fromtimestamp(stats['last_used']).strftime('%Y-%m-%d %H:%M:%S')
    print(f"    Láº§n cuá»‘i sá»­ dá»¥ng: {last_used_time_str}")
    print(f"    Sá»‘ láº§n tháº¥t báº¡i liÃªn tiáº¿p: {stats['failures']}")
    rate_limited_until_time_str = "KhÃ´ng bá»‹ giá»›i háº¡n"
    if stats['rate_limited_until'] > time.time():
        rate_limited_until_time_str = datetime.datetime.fromtimestamp(stats['rate_limited_until']).strftime('%Y-%m-%d %H:%M:%S')
    print(f"    Bá»‹ giá»›i háº¡n Ä‘áº¿n: {rate_limited_until_time_str}")
```

## âš ï¸ Xá»­ lÃ½ lá»—i

ThÆ° viá»‡n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ xá»­ lÃ½ lá»—i má»™t cÃ¡ch linh hoáº¡t thÃ´ng qua cÃ¡c chiáº¿n lÆ°á»£c vÃ  quáº£n lÃ½ key. Tuy nhiÃªn, báº¡n váº«n cáº§n kiá»ƒm tra káº¿t quáº£ tráº£ vá».

*   **Kiá»ƒm tra `response['success']` (boolean):** ÄÃ¢y lÃ  chá»‰ bÃ¡o chÃ­nh vá» thÃ nh cÃ´ng hay tháº¥t báº¡i cá»§a yÃªu cáº§u *tá»•ng thá»ƒ*.
*   **Kiá»ƒm tra `response['error']`:** Náº¿u `success` lÃ  `False`, trÆ°á»ng nÃ y sáº½ chá»©a thÃ´ng tin lá»—i (vÃ­ dá»¥: "Max retries exceeded", "All models failed", "Rate limit exceeded", "Copyright material detected", lá»—i API gá»‘c, lá»—i phÃ¢n tÃ­ch JSON).
*   **Lá»—i Rate Limit (`429`):** `KeyRotationManager` sáº½ tá»± Ä‘á»™ng xá»­ lÃ½ lá»—i nÃ y báº±ng cÃ¡ch Ä‘Ã¡nh dáº¥u key lÃ  bá»‹ giá»›i háº¡n vÃ  chá»n key khÃ¡c (dá»±a trÃªn `key_strategy`). Náº¿u táº¥t cáº£ cÃ¡c key Ä‘á»u bá»‹ giá»›i háº¡n, cÃ¡c chiáº¿n lÆ°á»£c cÃ³ thá»ƒ tháº¥t báº¡i vÃ  tráº£ vá» lá»—i.
*   **Lá»—i Báº£n quyá»n:** Pháº£n há»“i bá»‹ cháº·n do vi pháº¡m báº£n quyá»n (`finish_reason == 4` trong API response gá»‘c) sáº½ Ä‘Æ°á»£c `ResponseHandler` phÃ¡t hiá»‡n vÃ  tráº£ vá» `success=False` cÃ¹ng thÃ´ng bÃ¡o lá»—i cá»¥ thá»ƒ.
*   **Lá»—i PhÃ¢n tÃ­ch JSON:** Khi yÃªu cáº§u Ä‘áº§u ra cÃ³ cáº¥u trÃºc (`response_mime_type="application/json"`), `ResponseHandler` sáº½ cá»‘ gáº¯ng phÃ¢n tÃ­ch cÃº phÃ¡p pháº£n há»“i text thÃ nh JSON. Náº¿u tháº¥t báº¡i, `success` sáº½ lÃ  `False` vÃ  `error` sáº½ chá»‰ ra lá»—i phÃ¢n tÃ­ch.
*   **Lá»—i File API:** CÃ¡c lá»—i liÃªn quan Ä‘áº¿n táº£i lÃªn, láº¥y hoáº·c xÃ³a file sáº½ Ä‘Æ°á»£c tráº£ vá» trong dictionary káº¿t quáº£ cá»§a cÃ¡c phÆ°Æ¡ng thá»©c `upload_file`, `get_file`, `delete_file`, v.v.
*   **`response['model']`:** Cho biáº¿t model cuá»‘i cÃ¹ng Ä‘Æ°á»£c thá»­ (cÃ³ thá»ƒ lÃ  model gÃ¢y lá»—i hoáº·c model fallback).
*   **`response['attempts']`:** Chá»‰ cÃ³ Ã½ nghÄ©a vá»›i chiáº¿n lÆ°á»£c `RETRY`, cho biáº¿t sá»‘ láº§n Ä‘Ã£ thá»­.

```python
# VÃ­ dá»¥ xá»­ lÃ½ lá»—i rÃµ rÃ ng hÆ¡n
prompt_nguy_hiem = "Prompt vi pháº¡m chÃ­nh sÃ¡ch ná»™i dung" # VÃ­ dá»¥
response = handler.generate_content(prompt_nguy_hiem)

if response['success']:
    print("ThÃ nh cÃ´ng:")
    print(response['text'])
else:
    print("="*10 + " Lá»–I Xáº¢Y RA " + "="*10)
    print(f"ThÃ´ng bÃ¡o lá»—i: {response['error']}")
    print(f"Model cuá»‘i cÃ¹ng thá»­: {response['model']}")
    print(f"Index Key cuá»‘i cÃ¹ng thá»­: {response['api_key_index']}")
    if 'attempts' in response: # Kiá»ƒm tra náº¿u cÃ³ thÃ´ng tin attempts
        print(f"Sá»‘ láº§n thá»­ (Retry strategy): {response['attempts']}")

    # Xá»­ lÃ½ cá»¥ thá»ƒ dá»±a trÃªn loáº¡i lá»—i (vÃ­ dá»¥)
    if "Copyright material detected" in response['error']:
        print("-> Lá»—i nÃ y do ná»™i dung báº£n quyá»n, thá»­ láº¡i vá»›i prompt khÃ¡c.")
    elif "Rate limit" in response['error']:
        print("-> Lá»—i nÃ y do giá»›i háº¡n request, há»‡ thá»‘ng sáº½ tá»± chuyá»ƒn key.")
    elif "Failed to parse JSON" in response['error']:
        print("-> Lá»—i nÃ y do model khÃ´ng tráº£ vá» JSON há»£p lá»‡, kiá»ƒm tra láº¡i prompt hoáº·c schema.")
    # ... thÃªm cÃ¡c xá»­ lÃ½ lá»—i khÃ¡c
```

## âš™ï¸ Sá»­ dá»¥ng Biáº¿n MÃ´i trÆ°á»ng (NgoÃ i file YAML)

Báº¡n cÃ³ thá»ƒ cáº¥u hÃ¬nh má»™t sá»‘ tham sá»‘ chÃ­nh thÃ´ng qua biáº¿n mÃ´i trÆ°á»ng. ChÃºng thÆ°á»ng **ghi Ä‘Ã¨** cÃ¡c giÃ¡ trá»‹ tÆ°Æ¡ng á»©ng trong file YAML (trá»« `api_keys` cÃ³ thá»© tá»± Æ°u tiÃªn riÃªng nhÆ° Ä‘Ã£ nÃªu). Proxy cÅ©ng cÃ³ thá»ƒ bá»‹ ghi Ä‘Ã¨ bá»Ÿi `HTTP_PROXY`/`HTTPS_PROXY`.

```bash
# API Keys (Æ°u tiÃªn cao hÆ¡n YAML náº¿u Ä‘Æ°á»£c Ä‘áº·t)
export GEMINI_API_KEYS="key1,key2,key3"
# export GEMINI_API_KEY="key-cua-ban" # Chá»‰ dÃ¹ng náº¿u GEMINI_API_KEYS khÃ´ng cÃ³

# Proxy (sáº½ ghi Ä‘Ã¨ proxy trong YAML hoáº·c proxy_settings)
export HTTP_PROXY="http://proxy.server:port"
export HTTPS_PROXY="http://proxy.server:port"

# CÃ i Ä‘áº·t khÃ¡c (Ã­t dÃ¹ng hÆ¡n, thÆ°á»ng nÃªn Ä‘áº·t trong YAML hoáº·c code)
# export GEMINI_DEFAULT_MODEL="gemini-1.5-pro"
# CÃ¡c cÃ i Ä‘áº·t nhÆ° rate limit, strategies, retry thÆ°á»ng Ä‘Æ°á»£c Ä‘áº·t trong YAML hoáº·c khi khá»Ÿi táº¡o handler.
# Biáº¿n mÃ´i trÆ°á»ng cho server CLI (náº¿u khÃ´ng dÃ¹ng --args):
# export GEMINI_HOST="127.0.0.1"
# export GEMINI_PORT="9000"
```

**LÆ°u Ã½:** Viá»‡c sá»­ dá»¥ng biáº¿n mÃ´i trÆ°á»ng tiá»‡n lá»£i cho cáº¥u hÃ¬nh Ä‘Æ¡n giáº£n hoáº·c trong mÃ´i trÆ°á»ng container, nhÆ°ng file YAML cung cáº¥p kháº£ nÄƒng cáº¥u hÃ¬nh chi tiáº¿t vÃ  cÃ³ cáº¥u trÃºc hÆ¡n.

## ðŸš€ VÃ­ dá»¥ thá»±c táº¿: XÃ¢y dá»±ng Chatbot Bá»n bá»‰

VÃ­ dá»¥ nÃ y sá»­ dá»¥ng `GeminiHandler` vá»›i cÃ¡c chiáº¿n lÆ°á»£c phÃ¹ há»£p Ä‘á»ƒ táº¡o ra má»™t chatbot cÃ³ kháº£ nÄƒng xá»­ lÃ½ lá»—i vÃ  rate limit tá»‘t hÆ¡n.

```python
from gemini_handler import GeminiHandler, Strategy, KeyRotationStrategy
import sys
import time

# Khá»Ÿi táº¡o handler vá»›i chiáº¿n lÆ°á»£c tá»‘i Æ°u cho chatbot
try:
    chatbot_handler = GeminiHandler(
        config_path="config.yaml", # Äáº£m báº£o file nÃ y tá»“n táº¡i vÃ  cÃ³ key, proxy náº¿u cáº§n
        content_strategy=Strategy.FALLBACK, # Æ¯u tiÃªn model tá»‘t, fallback náº¿u lá»—i
        key_strategy=KeyRotationStrategy.SMART_COOLDOWN, # Xá»­ lÃ½ rate limit tá»‘t
        system_instruction="Báº¡n lÃ  má»™t trá»£ lÃ½ áº£o thÃ¢n thiá»‡n vÃ  há»¯u Ã­ch tÃªn lÃ  GemiBot."
    )
    print("GemiBot: ÄÃ£ khá»Ÿi táº¡o thÃ nh cÃ´ng!")
    # In thá»‘ng kÃª key ban Ä‘áº§u (tÃ¹y chá»n)
    # print("Thá»‘ng kÃª key ban Ä‘áº§u:", json.dumps(chatbot_handler.get_key_stats(), indent=2))
except ValueError as e:
    print(f"Lá»—i khá»Ÿi táº¡o GeminiHandler: {e}")
    print("Vui lÃ²ng kiá»ƒm tra cáº¥u hÃ¬nh API key trong config.yaml hoáº·c biáº¿n mÃ´i trÆ°á»ng.")
    sys.exit(1) # ThoÃ¡t náº¿u khÃ´ng cÃ³ key
except FileNotFoundError:
    print("Lá»—i: KhÃ´ng tÃ¬m tháº¥y file config.yaml. Äang thá»­ khá»Ÿi táº¡o khÃ´ng cÃ³ config...")
    try:
         chatbot_handler = GeminiHandler(
            # Thá»­ náº¡p key tá»« ENV
            content_strategy=Strategy.FALLBACK,
            key_strategy=KeyRotationStrategy.SMART_COOLDOWN,
            system_instruction="Báº¡n lÃ  má»™t trá»£ lÃ½ áº£o thÃ¢n thiá»‡n vÃ  há»¯u Ã­ch tÃªn lÃ  GemiBot."
         )
         print("GemiBot: ÄÃ£ khá»Ÿi táº¡o thÃ nh cÃ´ng (sá»­ dá»¥ng API keys tá»« ENV).")
    except ValueError as e_env:
        print(f"Lá»—i khá»Ÿi táº¡o GeminiHandler tá»« ENV: {e_env}")
        sys.exit(1)


def chat_with_user():
    print("\nGemiBot: Xin chÃ o! TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n? (GÃµ 'táº¡m biá»‡t' Ä‘á»ƒ thoÃ¡t)")
    conversation_history = [] # LÆ°u trá»¯ lá»‹ch sá»­ dÆ°á»›i dáº¡ng [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]

    while True:
        user_input = input("Báº¡n: ")
        if user_input.lower() in ["táº¡m biá»‡t", "bye", "exit", "quit"]:
            print("GemiBot: Táº¡m biá»‡t! Háº¹n gáº·p láº¡i!")
            break

        # ThÃªm tin nháº¯n ngÆ°á»i dÃ¹ng vÃ o lá»‹ch sá»­
        conversation_history.append({"role": "user", "content": user_input})

        # Táº¡o prompt tá»« lá»‹ch sá»­ (Ä‘Æ¡n giáº£n, chá»‰ ná»‘i chuá»—i)
        # CÃ³ thá»ƒ cáº£i tiáº¿n Ä‘á»ƒ phÃ¹ há»£p hÆ¡n vá»›i cÃ¡ch model xá»­ lÃ½ ngá»¯ cáº£nh
        prompt_parts = []
        if chatbot_handler.system_instruction:
             prompt_parts.append(f"System: {chatbot_handler.system_instruction}")
        for msg in conversation_history:
             role = msg["role"]
             content = msg["content"]
             if role == "user":
                 prompt_parts.append(f"User: {content}")
             elif role == "assistant":
                 prompt_parts.append(f"Assistant: {content}")
        prompt = "\n\n".join(prompt_parts) + "\n\nAssistant:" # YÃªu cáº§u model Ä‘Ã³ng vai Assistant


        # Táº¡o pháº£n há»“i vá»›i xá»­ lÃ½ lá»—i tÃ­ch há»£p
        # Chiáº¿n lÆ°á»£c Fallback sáº½ tá»± Ä‘á»™ng thá»­ model khÃ¡c náº¿u cáº§n
        # model_to_try = "gemini-1.5-pro" # Æ¯u tiÃªn model máº¡nh (náº¿u cÃ³ trong config.models)
        model_to_try = chatbot_handler.config.default_model # Sá»­ dá»¥ng model máº·c Ä‘á»‹nh

        print("GemiBot: (Äang suy nghÄ©...)")
        start_time = time.time()
        response = chatbot_handler.generate_content(
            prompt=prompt,
            model_name=model_to_try,
            return_stats=True # Láº¥y thá»‘ng kÃª Ä‘á»ƒ debug
        )
        end_time = time.time()
        print(f"GemiBot: (Thá»i gian pháº£n há»“i: {end_time - start_time:.2f}s, Key: {response.get('api_key_index', 'N/A')})")


        # Hiá»ƒn thá»‹ káº¿t quáº£ hoáº·c thÃ´ng bÃ¡o lá»—i cuá»‘i cÃ¹ng
        if response['success']:
            bot_reply = response['text'].strip()
            print(f"GemiBot: {bot_reply}")
            # ThÃªm pháº£n há»“i cá»§a bot vÃ o lá»‹ch sá»­
            conversation_history.append({"role": "assistant", "content": bot_reply})
        else:
            error_msg = response['error']
            key_index = response.get('api_key_index', 'N/A')
            model_failed = response.get('model', 'N/A')
            print(f"GemiBot: Xin lá»—i, tÃ´i Ä‘ang gáº·p chÃºt váº¥n Ä‘á» ká»¹ thuáº­t.")
            print(f"  Lá»—i: {error_msg}")
            print(f"  (Model: {model_failed}, Key Index: {key_index})")

            # XÃ³a lÆ°á»£t há»i cá»§a ngÆ°á»i dÃ¹ng khá»i lá»‹ch sá»­ náº¿u bot lá»—i, trÃ¡nh láº·p láº¡i
            if conversation_history and conversation_history[-1]["role"] == "user":
                 conversation_history.pop()
            print("GemiBot: Vui lÃ²ng thá»­ láº¡i sau giÃ¢y lÃ¡t hoáº·c Ä‘áº·t cÃ¢u há»i khÃ¡c.")

        # Giá»›i háº¡n lá»‹ch sá»­ Ä‘á»ƒ trÃ¡nh prompt quÃ¡ dÃ i (vÃ­ dá»¥: giá»¯ 10 cáº·p thoáº¡i gáº§n nháº¥t)
        MAX_HISTORY_PAIRS = 10
        if len(conversation_history) > MAX_HISTORY_PAIRS * 2:
             conversation_history = conversation_history[-(MAX_HISTORY_PAIRS * 2):]

        # In thá»‘ng kÃª key sau má»—i vÃ i lÆ°á»£t (tÃ¹y chá»n)
        # if len(conversation_history) % 4 == 0: # VÃ­ dá»¥: in sau má»—i 2 lÆ°á»£t thoáº¡i
        #      print("\n--- Key Stats ---")
        #      print(json.dumps(chatbot_handler.get_key_stats(), indent=2))
        #      print("-----------------\n")


# Cháº¡y chatbot
if __name__ == "__main__":
    chat_with_user()
```

## ðŸ§© CÃ¡c ThÃ nh pháº§n ChÃ­nh

*   **`GeminiHandler`:** Class chÃ­nh, lÃ  Ä‘iá»ƒm truy cáº­p cho má»i tÆ°Æ¡ng tÃ¡c. Quáº£n lÃ½ cáº¥u hÃ¬nh, key, chiáº¿n lÆ°á»£c, vÃ  gá»i cÃ¡c API Gemini. Káº¿ thá»«a tá»« `ContentGenerationMixin` vÃ  `FileOperationsMixin`.
*   **`ContentGenerationMixin`:** Chá»©a cÃ¡c phÆ°Æ¡ng thá»©c táº¡o ná»™i dung (`generate_content`, `generate_structured_content`, `generate_embeddings`).
*   **`FileOperationsMixin`:** Chá»©a cÃ¡c phÆ°Æ¡ng thá»©c liÃªn quan Ä‘áº¿n file (`upload_file`, `get_file`, `list_files`, `delete_file`, `batch_upload_files`, `generate_content_with_file`, `generate_structured_content_with_file`, `generate_with_local_file`).
*   **`Strategy` (Enum):** Äá»‹nh nghÄ©a cÃ¡c chiáº¿n lÆ°á»£c táº¡o ná»™i dung (`ROUND_ROBIN`, `FALLBACK`, `RETRY`).
*   **`KeyRotationStrategy` (Enum):** Äá»‹nh nghÄ©a cÃ¡c chiáº¿n lÆ°á»£c luÃ¢n chuyá»ƒn API key (`SEQUENTIAL`, `ROUND_ROBIN`, `LEAST_USED`, `SMART_COOLDOWN`).
*   **`GenerationConfig`:** Dataclass Ä‘á»ƒ cáº¥u hÃ¬nh tham sá»‘ model nhÆ° `temperature`, `top_p`, `max_output_tokens`, `response_mime_type`, `response_schema`.
*   **`EmbeddingConfig`:** Dataclass cho tham sá»‘ embedding, bao gá»“m háº±ng sá»‘ `task_type`.
*   **`ModelResponse`:** Dataclass chuáº©n hÃ³a cho káº¿t quáº£ gá»i API, chá»©a `success` (bool), `model` (str), `text` (str), `structured_data` (dict), `embeddings` (list), `error` (str), `time` (float), `api_key_index` (int), `file_info` (dict).
*   **`KeyRotationManager`:** Xá»­ lÃ½ logic chá»n, theo dÃµi tráº¡ng thÃ¡i vÃ  luÃ¢n chuyá»ƒn API key dá»±a trÃªn chiáº¿n lÆ°á»£c vÃ  rate limit.
*   **`FileHandler`:** Lá»›p cáº¥p tháº¥p hÆ¡n chuyÃªn xá»­ lÃ½ tÆ°Æ¡ng tÃ¡c vá»›i Gemini File API (upload, get, list, delete). ÄÆ°á»£c `GeminiHandler` sá»­ dá»¥ng ná»™i bá»™.
*   **`EmbeddingHandler`:** Lá»›p chuyÃªn xá»­ lÃ½ viá»‡c gá»i API embedding, sá»­ dá»¥ng `KeyRotationManager`.
*   **`ResponseHandler`:** Xá»­ lÃ½ vÃ  chuáº©n hÃ³a pháº£n há»“i thÃ´ tá»« API Gemini, bao gá»“m kiá»ƒm tra lá»—i báº£n quyá»n vÃ  phÃ¢n tÃ­ch JSON.
*   **`strategies.py`:** Chá»©a cÃ¡c class triá»ƒn khai `ContentStrategy` (RoundRobinStrategy, FallbackStrategy, RetryStrategy).
*   **`config.py` (`ConfigLoader`):** Tiá»‡n Ã­ch náº¡p API key vÃ  proxy tá»« nhiá»u nguá»“n cho `GeminiHandler`.
*   **`proxy.py` (`ProxyManager`):** Quáº£n lÃ½ cáº¥u hÃ¬nh proxy cho cÃ¡c request HTTP.
*   **`server.py` (`GeminiServer`):** Implement server FastAPI tÆ°Æ¡ng thÃ­ch OpenAI.
*   **`cli.py`:** Giao diá»‡n dÃ²ng lá»‡nh Ä‘á»ƒ khá»Ÿi cháº¡y `GeminiServer`.
*   **`litellm_integration.py` (`LiteLLMGeminiAdapter`):** Adapter Ä‘á»ƒ tÃ­ch há»£p vá»›i LiteLLM.
*   **`config_loader.py` (`ServerConfig`):** (Ãt dÃ¹ng trá»±c tiáº¿p) Lá»›p cáº¥u hÃ¬nh riÃªng cho server, nhÆ°ng `cli.py` hiá»‡n Ä‘ang Ä‘á»c YAML trá»±c tiáº¿p.

## ðŸ“„ Giáº¥y phÃ©p

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t hÃ nh theo Giáº¥y phÃ©p MIT - xem file `LICENSE` Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t. (Báº¡n nÃªn táº¡o file `LICENSE` chá»©a ná»™i dung giáº¥y phÃ©p MIT náº¿u chÆ°a cÃ³).

## ðŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n! Vui lÃ²ng táº¡o Pull Request hoáº·c má»Ÿ Issue náº¿u báº¡n cÃ³ Ã½ tÆ°á»Ÿng cáº£i tiáº¿n hoáº·c phÃ¡t hiá»‡n lá»—i.

Quy trÃ¬nh Ä‘Ã³ng gÃ³p Ä‘á» xuáº¥t:
1.  Fork kho lÆ°u trá»¯.
2.  Táº¡o má»™t nhÃ¡nh má»›i (`git checkout -b feature/ten-tinh-nang-cua-ban`).
3.  Thá»±c hiá»‡n cÃ¡c thay Ä‘á»•i cá»§a báº¡n.
4.  ThÃªm unit test cho cÃ¡c thay Ä‘á»•i (náº¿u cÃ³ thá»ƒ).
5.  Äáº£m báº£o táº¥t cáº£ cÃ¡c test Ä‘á»u pass.
6.  Format code cá»§a báº¡n (vÃ­ dá»¥: dÃ¹ng Black, Flake8).
7.  Commit cÃ¡c thay Ä‘á»•i (`git commit -m 'Them tinh nang X'`).
8.  Push lÃªn nhÃ¡nh (`git push origin feature/ten-tinh-nang-cua-ban`).
9.  Má»Ÿ má»™t Pull Request.
