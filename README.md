# Gemini Handler üöÄ

[![Gi·∫•y ph√©p: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
<!-- [![Tr·∫°ng th√°i Build](https://img.shields.io/travis/com/your-username/gemini-handler.svg)](https://travis-ci.com/your-username/gemini-handler) --> <!-- C·∫≠p nh·∫≠t li√™n k·∫øt CI/CD n·∫øu c√≥ -->

**Th∆∞ vi·ªán Python m·∫°nh m·∫Ω gi√∫p t∆∞∆°ng t√°c hi·ªáu qu·∫£ v·ªõi API Gemini c·ªßa Google, t√≠ch h·ª£p c√°c t√≠nh nƒÉng qu·∫£n l√Ω API key th√¥ng minh, chi·∫øn l∆∞·ª£c x·ª≠ l√Ω l·ªói linh ho·∫°t, kh·∫£ nƒÉng x·ª≠ l√Ω file, t·∫°o ƒë·∫ßu ra c√≥ c·∫•u tr√∫c, h·ªó tr·ª£ proxy, v√† cung c·∫•p m·ªôt server t∆∞∆°ng th√≠ch OpenAI.**

`gemini-handler` ƒë∆°n gi·∫£n h√≥a c√°c t√°c v·ª• ph·ªï bi·∫øn v√† tƒÉng c∆∞·ªùng ƒë·ªô b·ªÅn cho c√°c ·ª©ng d·ª•ng s·ª≠ d·ª•ng Gemini c·ªßa b·∫°n. Th∆∞ vi·ªán qu·∫£n l√Ω th√¥ng minh nhi·ªÅu API key ƒë·ªÉ gi·∫£m thi·ªÉu gi·ªõi h·∫°n t·ªëc ƒë·ªô (rate limit), cung c·∫•p nhi·ªÅu chi·∫øn l∆∞·ª£c x·ª≠ l√Ω l·ªói API, c√°c ph∆∞∆°ng th·ª©c ti·ªán l·ª£i cho vi·ªác t·∫°o vƒÉn b·∫£n, t·∫°o embedding, thao t√°c file, t·∫°o d·ªØ li·ªáu c√≥ c·∫•u tr√∫c (JSON), v√† t√≠ch h·ª£p d·ªÖ d√†ng v·ªõi c√°c h·ªá th·ªëng kh√°c th√¥ng qua server API ho·∫∑c adapter LiteLLM.

## ‚ú® T√≠nh nƒÉng n·ªïi b·∫≠t

*   **ü§ñ H·ªó tr·ª£ nhi·ªÅu Model Gemini:** T∆∞∆°ng t√°c v·ªõi c√°c model Gemini kh√°c nhau cho t√°c v·ª• vƒÉn b·∫£n, embedding v√† h√¨nh ·∫£nh (vision).
*   **üîë Qu·∫£n l√Ω API Key N√¢ng cao:**
    *   N·∫°p key t·ª´ danh s√°ch, bi·∫øn m√¥i tr∆∞·ªùng (`GEMINI_API_KEY`, `GEMINI_API_KEYS`) ho·∫∑c file c·∫•u h√¨nh YAML.
    *   Nhi·ªÅu chi·∫øn l∆∞·ª£c lu√¢n chuy·ªÉn key (`ROUND_ROBIN`, `SEQUENTIAL`, `LEAST_USED`, `SMART_COOLDOWN`) ƒë·ªÉ ph√¢n ph·ªëi t·∫£i v√† x·ª≠ l√Ω rate limit m∆∞·ª£t m√†.
    *   T·ª± ƒë·ªông "l√†m m√°t" (cooldown) cho c√°c key b·ªã gi·ªõi h·∫°n t·ªëc ƒë·ªô.
    *   Theo d√µi th·ªëng k√™ s·ª≠ d·ª•ng key (s·ªë l·∫ßn d√πng, l·ªói, th·ªùi gian b·ªã gi·ªõi h·∫°n).
*   **üîÑ T·∫°o N·ªôi dung B·ªÅn b·ªâ:**
    *   **Chi·∫øn l∆∞·ª£c Retry (Th·ª≠ l·∫°i):** T·ª± ƒë·ªông th·ª≠ l·∫°i c√°c y√™u c·∫ßu th·∫•t b·∫°i v·ªõi ƒë·ªô tr·ªÖ c√≥ th·ªÉ c·∫•u h√¨nh.
    *   **Chi·∫øn l∆∞·ª£c Fallback (D·ª± ph√≤ng):** Th·ª≠ t·∫°o n·ªôi dung v·ªõi m·ªôt chu·ªói c√°c model n·∫øu model ch√≠nh th·∫•t b·∫°i.
    *   **Chi·∫øn l∆∞·ª£c Round Robin (Lu√¢n phi√™n):** L·∫ßn l∆∞·ª£t th·ª≠ qua c√°c model c√≥ s·∫µn.
*   **üìÑ ƒê·∫ßu ra c√≥ c·∫•u tr√∫c (JSON):** T·∫°o n·ªôi dung tu√¢n th·ªß nghi√™m ng·∫∑t theo m·ªôt JSON schema ƒë∆∞·ª£c cung c·∫•p, t·ª± ƒë·ªông ph√¢n t√≠ch c√∫ ph√°p JSON t·ª´ ph·∫£n h·ªìi.
*   **üñºÔ∏è X·ª≠ l√Ω File:**
    *   T·∫£i file c·ª•c b·ªô l√™n API Gemini.
    *   Qu·∫£n l√Ω c√°c file ƒë√£ t·∫£i l√™n (l·∫•y th√¥ng tin, li·ªát k√™, x√≥a).
    *   T·ª± ƒë·ªông ch·ªù file chuy·ªÉn sang tr·∫°ng th√°i `ACTIVE` tr∆∞·ªõc khi s·ª≠ d·ª•ng.
    *   T·∫£i h√†ng lo·∫°t file t·ª´ m·ªôt th∆∞ m·ª•c.
*   **üëÅÔ∏è Kh·∫£ nƒÉng Vision:**
    *   T·∫°o n·ªôi dung d·ª±a tr√™n h√¨nh ·∫£nh/file ƒë√£ t·∫£i l√™n (t·ª± ƒë·ªông t·∫£i n·ªôi dung file khi c·∫ßn).
    *   T·∫°o n·ªôi dung tr·ª±c ti·∫øp t·ª´ file h√¨nh ·∫£nh c·ª•c b·ªô m√† kh√¥ng c·∫ßn t·∫£i l√™n tr∆∞·ªõc.
*   **üí° T·∫°o Embedding:** T·∫°o embedding vƒÉn b·∫£n s·ª≠ d·ª•ng c√°c model embedding Gemini ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh, h·ªó tr·ª£ `task_type`.
*   **‚öôÔ∏è T√πy ch·ªânh Linh ho·∫°t:** C·∫•u h√¨nh c√°c tham s·ªë t·∫°o n·ªôi dung (temperature, top_p, v.v.) v√† `system_instruction`.
*   **üìä Ph·∫£n h·ªìi Chu·∫©n h√≥a:** ƒê·ªëi t∆∞·ª£ng `ModelResponse` nh·∫•t qu√°n cho m·ªçi k·∫øt qu·∫£, bao g·ªìm tr·∫°ng th√°i th√†nh c√¥ng, vƒÉn b·∫£n/d·ªØ li·ªáu, l·ªói, th·ªùi gian x·ª≠ l√Ω, th√¥ng tin key v√† file ƒë√£ s·ª≠ d·ª•ng.
*   **üåê H·ªó tr·ª£ Proxy:** D·ªÖ d√†ng c·∫•u h√¨nh HTTP/HTTPS proxy th√¥ng qua file c·∫•u h√¨nh, tham s·ªë kh·ªüi t·∫°o ho·∫∑c bi·∫øn m√¥i tr∆∞·ªùng.
*   **üîå Server T∆∞∆°ng th√≠ch OpenAI:** Ch·∫°y m·ªôt server API (FastAPI) v·ªõi c√°c endpoint `/v1/chat/completions`, `/v1/embeddings`, `/v1/models` t∆∞∆°ng t·ª± OpenAI, cho ph√©p t√≠ch h·ª£p d·ªÖ d√†ng v·ªõi c√°c c√¥ng c·ª• hi·ªán c√≥.
*   **üöÄ Giao di·ªán D√≤ng l·ªánh (CLI):** Kh·ªüi ch·∫°y server API nhanh ch√≥ng t·ª´ terminal.
*   **üß© T√≠ch h·ª£p LiteLLM:** Adapter t√≠ch h·ª£p s·∫µn ƒë·ªÉ s·ª≠ d·ª•ng `gemini-handler` nh∆∞ m·ªôt custom provider trong LiteLLM.

## üõ†Ô∏è C√†i ƒë·∫∑t

ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√†i ƒë·∫∑t Python (>= 3.8).

1.  **C√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt:**
    ```bash
    pip install google-generativeai PyYAML requests Pillow fastapi uvicorn litellm # Th√™m litellm n·∫øu c·∫ßn
    ```
    *   `google-generativeai`: Th∆∞ vi·ªán ch√≠nh th·ª©c c·ªßa Google.
    *   `PyYAML`: ƒê·ªÉ ƒë·ªçc file c·∫•u h√¨nh `.yaml`.
    *   `requests`: ƒê∆∞·ª£c d√πng n·ªôi b·ªô (v√≠ d·ª•: t·∫£i file t·ª´ URI).
    *   `Pillow`: ƒê·ªÉ x·ª≠ l√Ω file h√¨nh ·∫£nh c·ª•c b·ªô.
    *   `fastapi`, `uvicorn`: ƒê·ªÉ ch·∫°y server API t∆∞∆°ng th√≠ch OpenAI.
    *   `litellm`: N·∫øu b·∫°n mu·ªën s·ª≠ d·ª•ng t√≠ch h·ª£p LiteLLM.

2.  **C√†i ƒë·∫∑t `gemini-handler`:**
    *   **T·ª´ m√£ ngu·ªìn (khuy·∫øn ngh·ªã hi·ªán t·∫°i):**
        ```bash
        git clone https://github.com/lethanhson9901/gemini-handler.git # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n repo th·ª±c t·∫ø
        cd gemini-handler
        pip install -e .
        ```
    *   **(Khi ƒë∆∞·ª£c xu·∫•t b·∫£n)**
        ```bash
        # pip install gemini-handler
        ```

## üîë C·∫•u h√¨nh: API Keys v√† Proxy

`gemini-handler` c·∫ßn c√°c API key Google Gemini v√† c√≥ th·ªÉ s·ª≠ d·ª•ng proxy.

### API Keys

Th∆∞ vi·ªán s·∫Ω n·∫°p key theo th·ª© t·ª± ∆∞u ti√™n sau:

1.  **Danh s√°ch key truy·ªÅn tr·ª±c ti·∫øp (Code):** Cung c·∫•p `api_keys=['key1', 'key2']` khi kh·ªüi t·∫°o `GeminiHandler`.
2.  **File C·∫•u h√¨nh YAML:** Cung c·∫•p `config_path="duong/dan/toi/config.yaml"` khi kh·ªüi t·∫°o. File YAML c·∫ßn c√≥ c·∫•u tr√∫c (xem v√≠ d·ª• chi ti·∫øt b√™n d∆∞·ªõi).
3.  **Bi·∫øn M√¥i tr∆∞·ªùng (Nhi·ªÅu Keys):** ƒê·∫∑t bi·∫øn `GEMINI_API_KEYS` l√† m·ªôt chu·ªói c√°c key, ph√¢n t√°ch b·ªüi d·∫•u ph·∫©y:
    ```bash
    export GEMINI_API_KEYS="API_KEY_CUA_BAN_1,API_KEY_CUA_BAN_2,API_KEY_CUA_BAN_3"
    ```
4.  **Bi·∫øn M√¥i tr∆∞·ªùng (M·ªôt Key):** ƒê·∫∑t bi·∫øn `GEMINI_API_KEY`:
    ```bash
    export GEMINI_API_KEY="API_KEY_DUY_NHAT_CUA_BAN"
    ```

N·∫øu kh√¥ng t√¨m th·∫•y key n√†o qua c√°c ph∆∞∆°ng th·ª©c tr√™n, th∆∞ vi·ªán s·∫Ω b√°o l·ªói `ValueError`.

### Proxy

Proxy c√≥ th·ªÉ ƒë∆∞·ª£c c·∫•u h√¨nh qua:

1.  **File C·∫•u h√¨nh YAML:** Xem m·ª•c `proxy` trong v√≠ d·ª• YAML.
2.  **Tham s·ªë `proxy_settings` (Code):** Cung c·∫•p dictionary `proxy_settings={'http': '...', 'https': '...'}` khi kh·ªüi t·∫°o `GeminiHandler`.
3.  **Bi·∫øn M√¥i tr∆∞·ªùng:** ƒê·∫∑t bi·∫øn `HTTP_PROXY` v√† `HTTPS_PROXY`. Bi·∫øn m√¥i tr∆∞·ªùng s·∫Ω **ghi ƒë√®** c√†i ƒë·∫∑t t·ª´ file YAML ho·∫∑c tham s·ªë `proxy_settings`.
    ```bash
    export HTTP_PROXY="http://user:pass@your-proxy.com:port"
    export HTTPS_PROXY="http://user:pass@your-proxy.com:port" # C√≥ th·ªÉ gi·ªëng http
    ```

### C·∫•u h√¨nh YAML Chi ti·∫øt (`config.yaml`)

B·∫°n c√≥ th·ªÉ t√πy ch·ªânh s√¢u h∆°n trong file `config.yaml`:

```yaml
# config.yaml v√≠ d·ª• ƒë·∫ßy ƒë·ªß
gemini:
  # API Keys (b·∫Øt bu·ªôc)
  api_keys:
    - "AIzaSyBmWf7COPcA6r62lDUoZ3x0dp47iy7ttSk" # lethanhson99907
    - "AIzaSyAIsEdv54bT-UixRDnG5aoOGXbGaybPHMM" # lethanhson99908
    # - "..."

  # C√†i ƒë·∫∑t t·∫°o n·ªôi dung m·∫∑c ƒë·ªãnh (t√πy ch·ªçn)
  generation:
    temperature: 0.7          # ƒê·ªô s√°ng t·∫°o (0.0-1.0)
    top_p: 1.0                # Ng∆∞·ª°ng x√°c su·∫•t t√≠ch l≈©y
    top_k: 40                 # S·ªë token c√≥ x√°c su·∫•t cao nh·∫•t ƒë·ªÉ xem x√©t
    max_output_tokens: 8192   # ƒê·ªô d√†i t·ªëi ƒëa ph·∫£n h·ªìi (token)
    stop_sequences: []        # Danh s√°ch chu·ªói d·ª´ng t·∫°o n·ªôi dung
    response_mime_type: "text/plain" # M·∫∑c ƒë·ªãnh l√† text, d√πng "application/json" cho structured output

  # Gi·ªõi h·∫°n t·ªëc ƒë·ªô m·∫∑c ƒë·ªãnh c·ªßa key (t√πy ch·ªçn) - D√πng cho KeyRotationManager
  rate_limits:
    requests_per_minute: 60   # S·ªë request t·ªëi ƒëa m·ªói ph√∫t tr√™n m·ªôt key
    reset_window: 60          # Th·ªùi gian (gi√¢y) ƒë·ªÉ b·ªô ƒë·∫øm request c·ªßa key reset v·ªÅ 0

  # Chi·∫øn l∆∞·ª£c m·∫∑c ƒë·ªãnh (t√πy ch·ªçn) - C√≥ th·ªÉ override khi kh·ªüi t·∫°o handler
  strategies:
    content: "round_robin"    # Chi·∫øn l∆∞·ª£c t·∫°o n·ªôi dung ('round_robin', 'fallback', 'retry')
    key_rotation: "smart_cooldown" # Chi·∫øn l∆∞·ª£c lu√¢n chuy·ªÉn key ('sequential', 'round_robin', 'least_used', 'smart_cooldown')

  # C√†i ƒë·∫∑t th·ª≠ l·∫°i m·∫∑c ƒë·ªãnh (t√πy ch·ªçn) - Ch·ªâ √°p d·ª•ng cho chi·∫øn l∆∞·ª£c 'retry'
  retry:
    max_attempts: 3           # S·ªë l·∫ßn th·ª≠ t·ªëi ƒëa cho m·ªôt y√™u c·∫ßu l·ªói
    delay: 30                 # Th·ªùi gian ch·ªù (gi√¢y) gi·ªØa c√°c l·∫ßn th·ª≠

  # Model m·∫∑c ƒë·ªãnh (t√πy ch·ªçn)
  default_model: "gemini-2.0-flash" # Model d√πng khi kh√¥ng ch·ªâ ƒë·ªãnh
  system_instruction: null      # System prompt m·∫∑c ƒë·ªãnh

  # C√†i ƒë·∫∑t Embedding (t√πy ch·ªçn)
  embedding:
    default_model: "gemini-embedding-exp-03-07" # Model embedding m·∫∑c ƒë·ªãnh
    # C√°c t√πy ch·ªçn kh√°c c√≥ th·ªÉ th√™m ·ªü ƒë√¢y n·∫øu c·∫ßn (v√≠ d·ª•: task_type m·∫∑c ƒë·ªãnh)
    # dimensions: 768 # Th√¥ng tin, kh√¥ng ph·∫£i c√†i ƒë·∫∑t tr·ª±c ti·∫øp
    # batch_size: 10 # Th√¥ng tin, kh√¥ng ph·∫£i c√†i ƒë·∫∑t tr·ª±c ti·∫øp
    # task_types: ... # Th√¥ng tin v·ªÅ c√°c task type h·ªó tr·ª£

# C√†i ƒë·∫∑t Proxy (t√πy ch·ªçn)
proxy:
  http: "http://brd-customer-hl_8d87b67a-zone-residential_proxy1:eb0e1vrv5v2g@brd.superproxy.io:33335"
  https: "https://brd-customer-hl_8d87b67a-zone-residential_proxy1:eb0e1vrv5v2g@brd.superproxy.io:33335"

# C√†i ƒë·∫∑t Server API (t√πy ch·ªçn) - C√°c gi√° tr·ªã n√†y c√≥ th·ªÉ b·ªã override b·ªüi CLI args
# server:
#   host: "0.0.0.0"
#   port: 8000
#   workers: 1 # S·ªë l∆∞·ª£ng worker (n·∫øu d√πng Gunicorn/Uvicorn n√¢ng cao)
#   log_level: "info"
# security: # C√†i ƒë·∫∑t b·∫£o m·∫≠t cho server API
#   require_auth: false # Y√™u c·∫ßu API key ƒë·ªÉ truy c·∫≠p server?
#   api_keys: [] # Danh s√°ch c√°c key h·ª£p l·ªá n·∫øu require_auth l√† true
```

## üöÄ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng `GeminiHandler`

### 1. Kh·ªüi t·∫°o C∆° b·∫£n

```python
from gemini_handler import GeminiHandler, Strategy, KeyRotationStrategy, GenerationConfig

# Kh·ªüi t·∫°o ƒë∆°n gi·∫£n nh·∫•t (n·∫°p key t·ª´ ENV ho·∫∑c config.yaml m·∫∑c ƒë·ªãnh n·∫øu c√≥)
try:
    handler_default = GeminiHandler()
except ValueError as e:
    print(f"L·ªói: {e}. Vui l√≤ng c·∫•u h√¨nh API keys.")
    # X·ª≠ l√Ω ho·∫∑c tho√°t

# Kh·ªüi t·∫°o v·ªõi danh s√°ch key, chi·∫øn l∆∞·ª£c v√† proxy c·ª• th·ªÉ
api_keys = ["API_KEY_CUA_BAN_1", "API_KEY_CUA_BAN_2"]
proxy_config = {
    'http': 'http://user:pass@proxy.example.com:8080',
    'https': 'http://user:pass@proxy.example.com:8080'
}
handler_custom = GeminiHandler(
    api_keys=api_keys,
    content_strategy=Strategy.RETRY,
    key_strategy=KeyRotationStrategy.SMART_COOLDOWN,
    proxy_settings=proxy_config # Truy·ªÅn c·∫•u h√¨nh proxy
)

# Kh·ªüi t·∫°o v·ªõi file c·∫•u h√¨nh v√† system instruction
system_instruction = "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch."
handler_with_config = GeminiHandler(
    config_path="config.yaml", # ƒê·ªçc c·∫£ API keys v√† proxy t·ª´ file (n·∫øu c√≥)
    system_instruction=system_instruction
)

# Kh·ªüi t·∫°o v·ªõi c·∫•u h√¨nh t·∫°o n·ªôi dung m·∫∑c ƒë·ªãnh kh√°c
custom_gen_config = GenerationConfig(temperature=0.5, max_output_tokens=1000)
handler_with_gen_config = GeminiHandler(
    api_keys=api_keys,
    generation_config=custom_gen_config
)

# G√°n handler b·∫°n mu·ªën s·ª≠ d·ª•ng cho bi·∫øn `handler`
handler = handler_with_config # V√≠ d·ª•: ch·ªçn handler ƒë·ªçc t·ª´ config
```

### 2. T·∫°o N·ªôi dung VƒÉn b·∫£n

```python
# ƒê·ªãnh nghƒ©a system prompt (n·∫øu ch∆∞a c√≥ khi kh·ªüi t·∫°o)
# handler.system_instruction = "B·∫°n l√† m·ªôt chuy√™n gia..." # C√≥ th·ªÉ g√°n l·∫°i n·∫øu c·∫ßn

prompt = "Gi·∫£i th√≠ch v·ªÅ ƒëi·ªán to√°n ƒë√°m m√¢y cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu."
response = handler.generate_content(prompt=prompt) # S·ª≠ d·ª•ng system instruction ƒë√£ g√°n

if response['success']:
    print("VƒÉn b·∫£n ƒë∆∞·ª£c t·∫°o:")
    print(response['text'])
    print(f"\nTh·ªùi gian th·ª±c hi·ªán: {response['time']:.2f}s")
    print(f"Index c·ªßa API Key ƒë√£ d√πng: {response['api_key_index']}")
else:
    print(f"L·ªói khi t·∫°o n·ªôi dung: {response['error']}")

# T·∫°o n·ªôi dung v·ªõi model c·ª• th·ªÉ v√† l·∫•y th·ªëng k√™ key
response_detailed = handler.generate_content(
    prompt="Vi·∫øt m·ªôt ƒëo·∫°n vƒÉn ng·∫Øn v·ªÅ l·ª£i √≠ch c·ªßa vi·ªác ƒë·ªçc s√°ch.",
    model_name="gemini-1.5-flash", # Ch·ªâ ƒë·ªãnh model
    return_stats=True             # L·∫•y th·ªëng k√™ s·ª≠ d·ª•ng key
)

if response_detailed['success']:
    print("\n" + response_detailed['text'])
    print("\nTh·ªëng k√™ Key:")
    import json
    print(json.dumps(response_detailed['key_stats'], indent=2))
else:
    print(f"L·ªói: {response_detailed['error']}")
```

### 3. T·∫°o D·ªØ li·ªáu c√≥ C·∫•u tr√∫c (JSON)

```python
import json

# ƒê·ªãnh nghƒ©a c·∫•u tr√∫c JSON mong mu·ªën (JSON Schema)
recipe_schema = {
    "type": "object",
    "properties": {
        "ten_mon_an": {"type": "string"},
        "nguyen_lieu": {"type": "array", "items": {"type": "string"}},
        "buoc_thuc_hien": {"type": "array", "items": {"type": "string"}},
        "thoi_gian_chuan_bi": {"type": "string", "description": "V√≠ d·ª•: 15 ph√∫t"},
        "thoi_gian_nau": {"type": "string", "description": "V√≠ d·ª•: 30 ph√∫t"}
    },
    "required": ["ten_mon_an", "nguyen_lieu", "buoc_thuc_hien"]
}

prompt = "Cho t√¥i c√¥ng th·ª©c l√†m m√≥n ph·ªü b√≤ H√† N·ªôi ƒë∆°n gi·∫£n t·∫°i nh√†."

# T·∫°o d·ªØ li·ªáu c√≥ c·∫•u tr√∫c
# L∆∞u √Ω: generate_structured_content t·ª± ƒë·ªông ƒë·∫∑t response_mime_type="application/json"
result = handler.generate_structured_content(
    prompt=prompt,
    schema=recipe_schema,
    model_name="gemini-1.5-pro", # N√™n d√πng model m·∫°nh h∆°n cho JSON ph·ª©c t·∫°p
    # temperature=0.2 # C√≥ th·ªÉ override tham s·ªë generation ·ªü ƒë√¢y
)

if result['success'] and result['structured_data']:
    print("\nD·ªØ li·ªáu c·∫•u tr√∫c ƒë∆∞·ª£c t·∫°o:")
    recipe = result['structured_data']
    print(json.dumps(recipe, indent=2, ensure_ascii=False))
    # print(f"\nVƒÉn b·∫£n g·ªëc t·ª´ API: {result['text']}") # H·ªØu √≠ch ƒë·ªÉ debug n·∫øu JSON parse l·ªói
elif result['success'] and not result['structured_data']:
     print(f"\nTh√†nh c√¥ng nh∆∞ng kh√¥ng ph√¢n t√≠ch ƒë∆∞·ª£c JSON t·ª´ ph·∫£n h·ªìi:")
     print(result['text'])
     print(f"L·ªói ph√¢n t√≠ch (n·∫øu c√≥): {result['error']}")
else:
    print(f"\nL·ªói khi t·∫°o d·ªØ li·ªáu c·∫•u tr√∫c: {result['error']}")

```

### 4. T·∫°o Embedding

```python
from gemini_handler import EmbeddingConfig # Import ƒë·ªÉ d√πng h·∫±ng s·ªë task_type

# handler = GeminiHandler(...) # ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√≥ instance handler

texts_to_embed = [
    "C√°ch m·∫°ng c√¥ng nghi·ªáp 4.0 l√† g√¨?",
    "Nh·ªØng ·ª©ng d·ª•ng ch√≠nh c·ªßa AI trong y t·∫ø.",
    "Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh ph·ªï bi·∫øn.",
]

# T·∫°o embedding ƒë∆°n gi·∫£n (s·ª≠ d·ª•ng model v√† task type m·∫∑c ƒë·ªãnh t·ª´ config)
response = handler.generate_embeddings(content=texts_to_embed)

if response['success']:
    print(f"\nƒê√£ t·∫°o {len(response['embeddings'])} embeddings.")
    # print(response['embeddings']) # Danh s√°ch c√°c vector embedding
    print(f"Vector ƒë·∫ßu ti√™n c√≥ {len(response['embeddings'][0])} chi·ªÅu.")
    print(f"Index c·ªßa API Key ƒë√£ d√πng: {response['api_key_index']}")
else:
    print(f"\nL·ªói khi t·∫°o embeddings: {response['error']}")

# T·∫°o embedding v·ªõi model v√† task_type c·ª• th·ªÉ
response_specific = handler.generate_embeddings(
    content="T√¨m ki·∫øm t√†i li·ªáu: th∆∞ vi·ªán Python t·ªët nh·∫•t cho web development",
    model_name="gemini-embedding-exp-03-07", # Ch·ªâ ƒë·ªãnh model embedding
    task_type=EmbeddingConfig.RETRIEVAL_QUERY, # Ch·ªâ ƒë·ªãnh lo·∫°i t√°c v·ª• l√† truy v·∫•n
    return_stats=True
)

# C√°c lo·∫°i task_type kh·∫£ d·ª•ng trong EmbeddingConfig:
# SEMANTIC_SIMILARITY, CLASSIFICATION, CLUSTERING, RETRIEVAL_DOCUMENT,
# RETRIEVAL_QUERY, QUESTION_ANSWERING, FACT_VERIFICATION, CODE_RETRIEVAL_QUERY

if response_specific['success']:
    print("\nEmbedding cho truy v·∫•n t√¨m ki·∫øm:")
    # print(response_specific['embeddings'])
    print("\nTh·ªëng k√™ Key:")
    print(json.dumps(response_specific['key_stats'], indent=2))
else:
    print(f"L·ªói: {response_specific['error']}")
```

### 5. Thao t√°c v·ªõi File (Upload, Qu·∫£n l√Ω, S·ª≠ d·ª•ng)

```python
from pathlib import Path
import time
import json # ƒê·ªÉ in ƒë·∫πp

# handler = GeminiHandler(...) # ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√≥ instance handler

# --- T·∫£i File L√™n ---
# file_path = "duong/dan/toi/hinh_anh_cua_ban.jpg" # Ho·∫∑c file PDF, video, audio... ƒë∆∞·ª£c h·ªó tr·ª£
file_path = Path("./cat_image.jpg") # V√≠ d·ª•: t·∫°o file ·∫£nh m√®o ƒë·ªÉ test
if not file_path.exists():
    # T·∫°o file ·∫£nh gi·∫£ n·∫øu ch∆∞a c√≥ (c·∫ßn Pillow)
    try:
        from PIL import Image
        img = Image.new('RGB', (60, 30), color = 'red')
        img.save(file_path)
        print(f"ƒê√£ t·∫°o file ·∫£nh gi·∫£: {file_path}")
    except ImportError:
        print("L·ªói: C·∫ßn c√†i Pillow ƒë·ªÉ t·∫°o ·∫£nh gi·∫£ (pip install Pillow)")
        # X·ª≠ l√Ω l·ªói ho·∫∑c tho√°t
        exit()
    except Exception as e:
         print(f"L·ªói khi t·∫°o ·∫£nh gi·∫£: {e}")
         exit()

print(f"\nƒêang t·∫£i l√™n file: {file_path}...")
upload_result = handler.upload_file(file_path)

if upload_result['success']:
    uploaded_file_object = upload_result['file'] # L·∫•y ƒë·ªëi t∆∞·ª£ng file g·ªëc t·ª´ Google API
    uploaded_file_name = uploaded_file_object.name # L·∫•y t√™n file d·∫°ng "files/..."
    print(f"File t·∫£i l√™n th√†nh c√¥ng: {uploaded_file_name}")
    print(f"URI: {uploaded_file_object.uri}")
    print(f"Tr·∫°ng th√°i ban ƒë·∫ßu: {uploaded_file_object.state.name}") # Truy c·∫≠p state.name

    # Ch·ªù file ƒë∆∞·ª£c x·ª≠ l√Ω (quan tr·ªçng!)
    print("ƒêang ch·ªù file x·ª≠ l√Ω...")
    active_file_object = None
    for _ in range(6): # Th·ª≠ t·ªëi ƒëa 6 l·∫ßn (30 gi√¢y)
        get_result = handler.get_file(uploaded_file_name)
        if get_result['success']:
            current_file_object = get_result['file']
            print(f"  Tr·∫°ng th√°i hi·ªán t·∫°i: {current_file_object.state.name}")
            if current_file_object.state.name == "ACTIVE":
                active_file_object = current_file_object
                break # Tho√°t v√≤ng l·∫∑p khi ƒë√£ ACTIVE
            elif current_file_object.state.name == "FAILED":
                 print("L·ªói: File x·ª≠ l√Ω th·∫•t b·∫°i tr√™n server.")
                 break
        else:
            print(f"L·ªói khi ki·ªÉm tra tr·∫°ng th√°i file: {get_result['error']}")
            # C√≥ th·ªÉ break ho·∫∑c th·ª≠ l·∫°i
        time.sleep(5) # ƒê·ª£i 5 gi√¢y gi·ªØa c√°c l·∫ßn ki·ªÉm tra

    if active_file_object:
        print("File ƒë√£ s·∫µn s√†ng ƒë·ªÉ s·ª≠ d·ª•ng.")

        # --- L·∫•y Th√¥ng tin File (ƒë√£ c√≥ t·ª´ v√≤ng l·∫∑p tr√™n) ---
        print(f"\nTh√¥ng tin file: {active_file_object.name}")
        print(f"  Tr·∫°ng th√°i: {active_file_object.state.name}")
        print(f"  Lo·∫°i MIME: {active_file_object.mime_type}")
        print(f"  K√≠ch th∆∞·ªõc: {active_file_object.size_bytes} bytes")

        # --- T·∫°o N·ªôi dung v·ªõi File ƒê√£ T·∫£i L√™n (VƒÉn b·∫£n) ---
        prompt_cho_file = "M√¥ t·∫£ chi ti·∫øt n·ªôi dung c·ªßa h√¨nh ·∫£nh n√†y."
        # S·ª≠ d·ª•ng t√™n file ho·∫∑c ƒë·ªëi t∆∞·ª£ng file ƒë√£ l·∫•y ƒë∆∞·ª£c
        file_gen_response = handler.generate_content_with_file(
            file=active_file_object, # Truy·ªÅn ƒë·ªëi t∆∞·ª£ng file ƒë√£ ACTIVE
            prompt=prompt_cho_file,
            model_name="gemini-1.5-pro" # B·∫Øt bu·ªôc d√πng model vision
        )
        if file_gen_response['success']:
            print("\nN·ªôi dung ƒë∆∞·ª£c t·∫°o t·ª´ File:")
            print(file_gen_response['text'])
            print(f"Th√¥ng tin file ƒë√£ d√πng: {file_gen_response['file_info']}")
        else:
            print(f"\nL·ªói khi t·∫°o n·ªôi dung t·ª´ file: {file_gen_response['error']}")

        # --- T·∫°o N·ªôi dung v·ªõi File ƒê√£ T·∫£i L√™n (JSON) ---
        image_schema = {
            "type": "object",
            "properties": {
                "description": {"type": "string"},
                "objects_detected": {"type": "array", "items": {"type": "string"}},
                "dominant_colors": {"type": "array", "items": {"type": "string"}}
            },
            "required": ["description", "objects_detected"]
        }
        structured_file_gen_response = handler.generate_structured_content_with_file(
             file=active_file_object,
             prompt="Ph√¢n t√≠ch h√¨nh ·∫£nh n√†y v√† tr√≠ch xu·∫•t th√¥ng tin theo c·∫•u tr√∫c y√™u c·∫ßu.",
             schema=image_schema,
             model_name="gemini-1.5-pro" # D√πng model vision h·ªó tr·ª£ JSON
        )
        if structured_file_gen_response['success'] and structured_file_gen_response['structured_data']:
            print("\nD·ªØ li·ªáu c·∫•u tr√∫c ƒë∆∞·ª£c t·∫°o t·ª´ File:")
            print(json.dumps(structured_file_gen_response['structured_data'], indent=2, ensure_ascii=False))
        else:
            print(f"\nL·ªói khi t·∫°o d·ªØ li·ªáu c·∫•u tr√∫c t·ª´ file: {structured_file_gen_response['error']}")

        # --- X√≥a File ---
        print(f"\nƒêang x√≥a file: {uploaded_file_name}...")
        delete_result = handler.delete_file(uploaded_file_name)
        if delete_result['success']:
            print(f"ƒê√£ x√≥a th√†nh c√¥ng file: {delete_result['deleted_file']}")
        else:
            print(f"L·ªói khi x√≥a file: {delete_result['error']}")

    else:
        print(f"File kh√¥ng chuy·ªÉn sang tr·∫°ng th√°i ACTIVE sau khi ch·ªù.")
        # C√¢n nh·∫Øc x√≥a file n·∫øu x·ª≠ l√Ω l·ªói ho·∫∑c kh√¥ng th√†nh c√¥ng
        # handler.delete_file(uploaded_file_name)

else:
    print(f"L·ªói khi t·∫£i file l√™n: {upload_result['error']}")

# --- Li·ªát k√™ Files ---
print("\nƒêang li·ªát k√™ c√°c file...")
list_result = handler.list_files(page_size=5) # L·∫•y t·ªëi ƒëa 5 file m·ªói trang
if list_result['success']:
    print("Danh s√°ch Files:")
    if list_result['files']:
        for f in list_result['files']:
             # Truy c·∫≠p state qua .name
             print(f" - {f['name']} ({f['mime_type']}, Tr·∫°ng th√°i: {f['state'].name if f.get('state') else 'N/A'})")
        # if list_result['next_page_token']: # FileHandler hi·ªán t·∫°i kh√¥ng tr·∫£ token d·ªÖ d√†ng
        #     print(f"C√≤n trang ti·∫øp theo (next_page_token): {list_result['next_page_token']}")
    else:
        print("  (Kh√¥ng c√≥ file n√†o)")
else:
    print(f"L·ªói khi li·ªát k√™ files: {list_result['error']}")

# --- T·∫£i H√†ng Lo·∫°t (Batch Upload) ---
# T·∫°o th∆∞ m·ª•c v√† file gi·∫£ ƒë·ªÉ v√≠ d·ª•
batch_dir = Path("temp_upload_dir")
batch_dir.mkdir(exist_ok=True)
(batch_dir / "tai_lieu_1.txt").write_text("N·ªôi dung file text 1.", encoding='utf-8')
(batch_dir / "hinh_anh_doc.png").touch() # T·∫°o file r·ªóng
(batch_dir / "script_util.py").write_text("print('Hello Utility')", encoding='utf-8')

print("\nƒêang t·∫£i l√™n h√†ng lo·∫°t t·ª´ th∆∞ m·ª•c 'temp_upload_dir'...")
batch_result = handler.batch_upload_files(
    directory_path=batch_dir,
    file_extensions=['.txt', '.png'] # Ch·ªâ t·∫£i file c√≥ ƒëu√¥i .txt ho·∫∑c .png
)
if batch_result['success']:
    print(f"ƒê√£ t·∫£i l√™n th√†nh c√¥ng {batch_result['count']} files:")
    uploaded_batch_files = []
    for f_info in batch_result['files']:
        print(f" - {f_info['name']} ({f_info['mime_type']})")
        uploaded_batch_files.append(f_info['name']) # L∆∞u t√™n ƒë·ªÉ x√≥a sau

    # D·ªçn d·∫πp c√°c file v·ª´a t·∫£i l√™n (v√≠ d·ª•)
    print("\nƒêang d·ªçn d·∫πp c√°c file v·ª´a batch upload...")
    # for file_name_to_delete in uploaded_batch_files:
    #     try:
    #         # Ch·ªù file ACTIVE tr∆∞·ªõc khi x√≥a n·∫øu c·∫ßn d√πng ngay
    #         # Ho·∫∑c x√≥a tr·ª±c ti·∫øp n·∫øu kh√¥ng c·∫ßn d√πng
    #         # C·∫ßn v√≤ng l·∫∑p ch·ªù t∆∞∆°ng t·ª± nh∆∞ upload ƒë∆°n l·∫ª n·∫øu mu·ªën ƒë·∫£m b·∫£o x√≥a ƒë∆∞·ª£c
    #         del_res = handler.delete_file(file_name_to_delete)
    #         if del_res['success']:
    #             print(f"  ƒê√£ x√≥a {file_name_to_delete}")
    #         else:
    #              print(f"  L·ªói x√≥a {file_name_to_delete}: {del_res['error']}")
    #     except Exception as e_del:
    #         print(f"  L·ªói ngo·∫°i l·ªá khi x√≥a {file_name_to_delete}: {e_del}")
else:
    print(f"L·ªói trong qu√° tr√¨nh t·∫£i h√†ng lo·∫°t: {batch_result['error']}")

# D·ªçn d·∫πp th∆∞ m·ª•c t·∫°m
import shutil
try:
    shutil.rmtree(batch_dir)
    print(f"\nƒê√£ x√≥a th∆∞ m·ª•c t·∫°m '{batch_dir}'.")
except OSError as e:
    print(f"L·ªói khi x√≥a th∆∞ m·ª•c t·∫°m: {e}")

# D·ªçn d·∫πp file ·∫£nh test ban ƒë·∫ßu
try:
    file_path.unlink(missing_ok=True)
    print(f"ƒê√£ x√≥a file ·∫£nh test '{file_path}'.")
except OSError as e:
    print(f"L·ªói khi x√≥a file ·∫£nh test: {e}")
```

### 6. T·∫°o N·ªôi dung v·ªõi File C·ª•c b·ªô (Kh√¥ng c·∫ßn Upload)

H·ªØu √≠ch cho vi·ªác ph√¢n t√≠ch nhanh h√¨nh ·∫£nh c·ª•c b·ªô m√† kh√¥ng c·∫ßn l∆∞u tr·ªØ ch√∫ng qua File API.

```python
from pathlib import Path
import json

# handler = GeminiHandler(...) # ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√≥ instance handler

local_image_path = Path("./local_image.jpeg")
if not local_image_path.exists():
    # T·∫°o file ·∫£nh gi·∫£ n·∫øu ch∆∞a c√≥
    try:
        from PIL import Image
        img = Image.new('RGB', (80, 40), color = 'blue')
        img.save(local_image_path)
        print(f"ƒê√£ t·∫°o file ·∫£nh gi·∫£ c·ª•c b·ªô: {local_image_path}")
    except ImportError:
        print("L·ªói: C·∫ßn c√†i Pillow ƒë·ªÉ t·∫°o ·∫£nh gi·∫£ (pip install Pillow)")
        exit()
    except Exception as e:
         print(f"L·ªói khi t·∫°o ·∫£nh gi·∫£: {e}")
         exit()

# --- T·∫°o VƒÉn b·∫£n t·ª´ ·∫¢nh C·ª•c b·ªô ---
print(f"\nƒêang t·∫°o n·ªôi dung t·ª´ file c·ª•c b·ªô: {local_image_path}...")
local_gen_response = handler.generate_with_local_file(
    file_path=local_image_path,
    prompt="C√≥ nh·ªØng ƒë·ªëi t∆∞·ª£ng n√†o trong b·ª©c ·∫£nh n√†y?",
    model_name="gemini-1.5-pro" # B·∫Øt bu·ªôc d√πng model vision
)

if local_gen_response['success']:
    print("\nN·ªôi dung ƒë∆∞·ª£c t·∫°o t·ª´ File C·ª•c b·ªô:")
    print(local_gen_response['text'])
    print(f"Th√¥ng tin file: {local_gen_response['file_info']}")
else:
    print(f"\nL·ªói khi t·∫°o n·ªôi dung t·ª´ file c·ª•c b·ªô: {local_gen_response['error']}")

# --- T·∫°o JSON t·ª´ ·∫¢nh C·ª•c b·ªô ---
local_structured_response = handler.generate_with_local_file(
    file_path=local_image_path,
    prompt="M√¥ t·∫£ ch·ªß th·ªÉ ch√≠nh v√† m√†u s·∫Øc ch·ªß ƒë·∫°o c·ªßa b·ª©c ·∫£nh n√†y.",
    schema={ # V√≠ d·ª• schema
        "type": "object",
        "properties": {
            "chu_the": {"type": "string"},
            "mau_sac": {"type": "array", "items": {"type": "string"}}
        },
        "required": ["chu_the", "mau_sac"]
    },
    model_name="gemini-1.5-pro" # D√πng model vision h·ªó tr·ª£ JSON
)

if local_structured_response['success'] and local_structured_response['structured_data']:
    print("\nD·ªØ li·ªáu c·∫•u tr√∫c ƒë∆∞·ª£c t·∫°o t·ª´ File C·ª•c b·ªô:")
    print(json.dumps(local_structured_response['structured_data'], indent=2, ensure_ascii=False))
else:
    print(f"\nL·ªói khi t·∫°o d·ªØ li·ªáu c·∫•u tr√∫c t·ª´ file c·ª•c b·ªô: {local_structured_response['error']}")

# D·ªçn d·∫πp file ·∫£nh test c·ª•c b·ªô
try:
    local_image_path.unlink(missing_ok=True)
    print(f"\nƒê√£ x√≥a file ·∫£nh c·ª•c b·ªô test '{local_image_path}'.")
except OSError as e:
    print(f"L·ªói khi x√≥a file ·∫£nh c·ª•c b·ªô test: {e}")

```

## üöÄ Ch·∫°y Server T∆∞∆°ng th√≠ch OpenAI

Th∆∞ vi·ªán bao g·ªìm m·ªôt server API d·ª±a tr√™n FastAPI, cung c·∫•p c√°c endpoint t∆∞∆°ng t·ª± OpenAI, cho ph√©p t√≠ch h·ª£p `gemini-handler` v·ªõi c√°c c√¥ng c·ª• v√† ·ª©ng d·ª•ng hi·ªán c√≥ h·ªó tr·ª£ API c·ªßa OpenAI.

### Ch·∫°y Server t·ª´ D√≤ng l·ªánh (CLI)

C√°ch d·ªÖ nh·∫•t ƒë·ªÉ kh·ªüi ch·∫°y server l√† s·ª≠ d·ª•ng CLI t√≠ch h·ª£p:

```bash
python -m gemini_handler.cli --config config.yaml --port 8000
```

**C√°c t√πy ch·ªçn CLI:**

*   `--host`: ƒê·ªãa ch·ªâ IP ƒë·ªÉ server l·∫Øng nghe (m·∫∑c ƒë·ªãnh: `0.0.0.0`).
*   `--port`: C·ªïng ƒë·ªÉ server l·∫Øng nghe (m·∫∑c ƒë·ªãnh: `8000`).
*   `--keys`: Danh s√°ch API key Gemini, ph√¢n t√°ch b·ªüi d·∫•u ph·∫©y (v√≠ d·ª•: `"key1,key2"`). **∆Øu ti√™n cao nh·∫•t**, s·∫Ω ghi ƒë√® key t·ª´ config ho·∫∑c ENV.
*   `--config`: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file c·∫•u h√¨nh YAML (m·∫∑c ƒë·ªãnh: `config.yaml`). Server s·∫Ω ƒë·ªçc c√°c c√†i ƒë·∫∑t nh∆∞ `api_keys`, `strategies`, `rate_limits`, `proxy`, `generation` t·ª´ file n√†y (n·∫øu kh√¥ng b·ªã override b·ªüi CLI args ho·∫∑c ENV).

Server s·∫Ω t·ª± ƒë·ªông s·ª≠ d·ª•ng c√°c chi·∫øn l∆∞·ª£c, qu·∫£n l√Ω key, v√† h·ªó tr·ª£ proxy ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh th√¥ng qua file YAML ho·∫∑c c√°c gi√° tr·ªã m·∫∑c ƒë·ªãnh.

### C√°c Endpoints c·ªßa Server

Server cung c·∫•p c√°c endpoint sau, t∆∞∆°ng th√≠ch v·ªõi ƒë·ªãnh d·∫°ng c·ªßa OpenAI API v1:

*   **`GET /v1/models`**: Li·ªát k√™ danh s√°ch c√°c model Gemini ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi server (v√≠ d·ª•: `gemini-1.5-pro`, `gemini-embedding-exp-03-07`).
*   **`POST /v1/chat/completions`**: T·∫°o ph·∫£n h·ªìi chat. Nh·∫≠n v√†o request body t∆∞∆°ng t·ª± OpenAI (v·ªõi `model`, `messages`, `temperature`, `max_tokens`, `stream` (hi·ªán ch∆∞a h·ªó tr·ª£), `response_format`={ "type": "json_object" }, v.v.). Server s·∫Ω chuy·ªÉn ƒë·ªïi `messages` th√†nh prompt v√† g·ªçi ph∆∞∆°ng th·ª©c `generate_content` ho·∫∑c `generate_structured_content` c·ªßa `GeminiHandler`.
*   **`POST /v1/embeddings`**: T·∫°o embeddings. Nh·∫≠n v√†o request body t∆∞∆°ng t·ª± OpenAI (v·ªõi `model`, `input`). Server s·∫Ω g·ªçi ph∆∞∆°ng th·ª©c `generate_embeddings` c·ªßa `GeminiHandler`.
*   **`GET /health`**: Endpoint ki·ªÉm tra s·ª©c kh·ªèe ƒë∆°n gi·∫£n, tr·∫£ v·ªÅ `{"status": "ok"}`.

### V√≠ d·ª• S·ª≠ d·ª•ng Server (v·ªõi `curl`)

```bash
# 1. L·∫•y danh s√°ch models
curl http://localhost:8000/v1/models

# 2. T·∫°o chat completion
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-1.5-flash",
    "messages": [
      {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω."},
      {"role": "user", "content": "Vi·∫øt c√¢u ch√†o bu·ªïi s√°ng."}
    ],
    "temperature": 0.7,
    "max_tokens": 50
  }'

# 3. T·∫°o chat completion y√™u c·∫ßu JSON output
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-1.5-pro",
    "messages": [
      {"role": "user", "content": "Cho t√¥i th√¥ng tin v·ªÅ Paris d∆∞·ªõi d·∫°ng JSON v·ªõi key l√† city v√† country."}
    ],
    "response_format": { "type": "json_object" }
  }'


# 4. T·∫°o embeddings
curl http://localhost:8000/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-embedding-exp-03-07",
    "input": "VƒÉn b·∫£n c·∫ßn t·∫°o embedding"
  }'

# 5. Ki·ªÉm tra health
curl http://localhost:8000/health
```

## üß© T√≠ch h·ª£p v·ªõi LiteLLM

S·ª≠ d·ª•ng `LiteLLMGeminiAdapter` ƒë·ªÉ t√≠ch h·ª£p `gemini-handler` nh∆∞ m·ªôt custom provider trong LiteLLM. ƒêi·ªÅu n√†y cho ph√©p b·∫°n t·∫≠n d·ª•ng c√°c t√≠nh nƒÉng qu·∫£n l√Ω key v√† chi·∫øn l∆∞·ª£c c·ªßa `gemini-handler` trong m√¥i tr∆∞·ªùng LiteLLM.

### C·∫•u h√¨nh LiteLLM

ƒêƒÉng k√Ω provider t√πy ch·ªânh trong code c·ªßa b·∫°n:

```python
import litellm
import os

# ƒê·∫£m b·∫£o gemini_handler ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t
# ƒêƒÉng k√Ω provider, tr·ªè ƒë·∫øn adapter class
litellm.register_provider(
    "custom_gemini",
    import_string="gemini_handler.LiteLLMGeminiAdapter" # ƒê∆∞·ªùng d·∫´n import ch√≠nh x√°c
)

# ---- C·∫•u h√¨nh API Keys cho Adapter ----
# ∆Øu ti√™n 1: ƒê·∫∑t bi·∫øn m√¥i tr∆∞·ªùng LiteLLM_GEMINI_API_KEY (LiteLLM khuy·∫øn ngh·ªã)
# os.environ["LITELLM_GEMINI_API_KEY"] = "key_cua_ban"

# ∆Øu ti√™n 2: ƒê·∫∑t bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEYS (ph√¢n t√°ch b·ªüi d·∫•u ph·∫©y)
os.environ["GEMINI_API_KEYS"] = "AIzaSyBmWf7COPcA6r62lDUoZ3x0dp47iy7ttSk,AIzaSyAIsEdv54bT-UixRDnG5aoOGXbGaybPHMM"

# ∆Øu ti√™n 3: ƒê·∫∑t bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY
# os.environ["GEMINI_API_KEY"] = "key_cua_ban"

# ∆Øu ti√™n 4: Truy·ªÅn tr·ª±c ti·∫øp khi g·ªçi (√≠t khuy·∫øn kh√≠ch h∆°n cho adapter d√πng chung)
# api_key_param = "key_cua_ban"

# L∆∞u √Ω: Adapter s·∫Ω ch·ªâ kh·ªüi t·∫°o handler m·ªôt l·∫ßn v√† t√°i s·ª≠ d·ª•ng.
# N√≥ s·∫Ω t√¨m key theo th·ª© t·ª±: LITELLM_GEMINI_API_KEY -> GEMINI_API_KEYS -> GEMINI_API_KEY.
# N·∫øu b·∫°n truy·ªÅn api_key khi g·ªçi litellm.completion, n√≥ s·∫Ω ƒë∆∞·ª£c ∆∞u ti√™n cho *l·∫ßn g·ªçi ƒë√≥*,
# nh∆∞ng kh√¥ng thay ƒë·ªïi handler d√πng chung tr·ª´ khi handler ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o.
```

### S·ª≠ d·ª•ng v·ªõi LiteLLM

G·ªçi c√°c h√†m c·ªßa LiteLLM, ch·ªâ ƒë·ªãnh model v·ªõi ti·ªÅn t·ªë `custom_gemini/`:

```python
# --- Chat Completion ---
try:
    response = litellm.completion(
        model="custom_gemini/gemini-1.5-pro", # S·ª≠ d·ª•ng ti·ªÅn t·ªë ƒë√£ ƒëƒÉng k√Ω
        messages=[
            {"role": "user", "content": "Hello, how are you?"}
        ],
        temperature=0.5
        # api_key=api_key_param # Ch·ªâ truy·ªÅn n·∫øu mu·ªën override cho l·∫ßn g·ªçi n√†y
    )
    print("\nLiteLLM Completion Response:")
    print(response)

    # L·∫•y n·ªôi dung tr·∫£ v·ªÅ
    if response and response.choices and response.choices[0].message:
         print("\nContent:", response.choices[0].message.content)

except Exception as e:
    print(f"\nL·ªói LiteLLM Completion: {e}")


# --- Embedding ---
try:
    embedding_response = litellm.embedding(
        model="custom_gemini/gemini-embedding-exp-03-07", # S·ª≠ d·ª•ng ti·ªÅn t·ªë
        input=["Your text to embed here", "Another text"]
        # api_key=api_key_param
    )
    print("\nLiteLLM Embedding Response:")
    # print(embedding_response)
    if embedding_response and embedding_response.data:
        print(f"Generated {len(embedding_response.data)} embeddings.")
        print(f"First embedding dimensions: {len(embedding_response.data[0].embedding)}")

except Exception as e:
    print(f"\nL·ªói LiteLLM Embedding: {e}")

```

Adapter s·∫Ω t·ª± ƒë·ªông chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng request/response gi·ªØa LiteLLM v√† `GeminiHandler`.

## üéØ C√°c chi·∫øn l∆∞·ª£c

### Chi·∫øn l∆∞·ª£c t·∫°o n·ªôi dung (`content_strategy`)

| Chi·∫øn l∆∞·ª£c         | M√¥ t·∫£                                                                   | Khi n√†o s·ª≠ d·ª•ng                                  |
| :----------------- | :---------------------------------------------------------------------- | :----------------------------------------------- |
| **`ROUND_ROBIN`**  | S·ª≠ d·ª•ng l·∫ßn l∆∞·ª£t c√°c model trong danh s√°ch `models` theo v√≤ng tr√≤n.       | Khi mu·ªën ph√¢n t√°n t·∫£i ƒë·ªÅu cho c√°c model.         |
| **`FALLBACK`**     | Th·ª≠ model ch·ªâ ƒë·ªãnh (ho·∫∑c model ƒë·∫ßu ti√™n), n·∫øu l·ªói th√¨ th·ª≠ model ti·∫øp theo. | Khi c·∫ßn ƒë·ªô tin c·∫≠y cao, ∆∞u ti√™n model t·ªët nh·∫•t. |
| **`RETRY`**        | Th·ª≠ l·∫°i c√πng m·ªôt model nhi·ªÅu l·∫ßn (theo `max_attempts`) khi g·∫∑p l·ªói.        | Khi mu·ªën nh·∫•t qu√°n v·ªÅ model s·ª≠ d·ª•ng cho 1 prompt. |

### Chi·∫øn l∆∞·ª£c lu√¢n chuy·ªÉn API key (`key_strategy`)

| Chi·∫øn l∆∞·ª£c             | M√¥ t·∫£                                                                                                | Khi n√†o s·ª≠ d·ª•ng                                          |
| :--------------------- | :--------------------------------------------------------------------------------------------------- | :------------------------------------------------------- |
| **`SEQUENTIAL`**       | S·ª≠ d·ª•ng c√°c key theo th·ª© t·ª± trong danh s√°ch, quay l·∫°i ƒë·∫ßu khi h·∫øt.                                    | ƒê∆°n gi·∫£n, khi mu·ªën ∆∞u ti√™n m·ªôt s·ªë key nh·∫•t ƒë·ªãnh.         |
| **`ROUND_ROBIN`**      | S·ª≠ d·ª•ng c√°c key l·∫ßn l∆∞·ª£t theo v√≤ng tr√≤n, b·ªè qua key b·ªã rate limit ho·∫∑c kh√¥ng kh·∫£ d·ª•ng.                 | Khi mu·ªën ph√¢n b·ªï ƒë·ªÅu c√°c request, d·ªÖ d·ª± ƒëo√°n.          |
| **`LEAST_USED`**       | ∆Øu ti√™n key c√≥ s·ªë l·∫ßn s·ª≠ d·ª•ng √≠t nh·∫•t trong kho·∫£ng `reset_window` v√† ƒëang kh·∫£ d·ª•ng.                   | Khi c·∫ßn c√¢n b·∫±ng t·∫£i th·ª±c t·∫ø gi·ªØa c√°c key.               |
| **`SMART_COOLDOWN`**   | T·ª± ƒë·ªông "l√†m m√°t" key b·ªã rate limit, ∆∞u ti√™n key √≠t l·ªói v√† ƒë√£ ngh·ªâ l√¢u nh·∫•t trong s·ªë key kh·∫£ d·ª•ng.   | Khi c·∫ßn kh·∫£ nƒÉng t·ª± ph·ª•c h·ªìi cao, t·ªëi ∆∞u khi key b·ªã limit. |

## üí° S·ª≠ d·ª•ng n√¢ng cao

### T√πy ch·ªânh chi·∫øn l∆∞·ª£c khi kh·ªüi t·∫°o

```python
from gemini_handler import GeminiHandler, Strategy, KeyRotationStrategy, GenerationConfig

# Kh·ªüi t·∫°o v·ªõi chi·∫øn l∆∞·ª£c t√πy ch·ªânh v√† override generation config
handler_advanced = GeminiHandler(
    config_path="config.yaml", # N·∫°p keys, proxy t·ª´ file
    content_strategy=Strategy.FALLBACK,         # D√πng chi·∫øn l∆∞·ª£c d·ª± ph√≤ng
    key_strategy=KeyRotationStrategy.LEAST_USED, # D√πng key √≠t s·ª≠ d·ª•ng nh·∫•t
    generation_config=GenerationConfig(temperature=0.8, top_k=50) # Override generation
)
# S·ª≠ d·ª•ng handler_advanced cho c√°c t√°c v·ª• ti·∫øp theo
```

### Theo d√µi hi·ªáu su·∫•t Request

```python
import json
import time

# T·∫°o n·ªôi dung v√† y√™u c·∫ßu tr·∫£ v·ªÅ th·ªëng k√™
response_perf = handler.generate_content(
    prompt="Vi·∫øt m·ªôt b√†i ph√¢n t√≠ch v·ªÅ xu h∆∞·ªõng AI nƒÉm 2024",
    return_stats=True # Quan tr·ªçng: ƒë·∫∑t l√† True
)

if response_perf['success']:
    print(response_perf['text'])
    print("-" * 20)
    print(f"Th·ªùi gian th·ª±c hi·ªán: {response_perf['time']:.2f} gi√¢y")
    print(f"Model ƒë√£ s·ª≠ d·ª•ng: {response_perf['model']}")
    print(f"Index Key ƒë√£ s·ª≠ d·ª•ng: {response_perf['api_key_index']}")
    print(f"S·ªë l·∫ßn th·ª≠ (n·∫øu d√πng Retry): {response_perf.get('attempts', 1)}") # attempts ch·ªâ c√≥ √Ω nghƒ©a v·ªõi Retry
    print("\nTh·ªëng k√™ Key:")
    print(json.dumps(response_perf['key_stats'], indent=2))

else:
    print(f"L·ªói: {response_perf['error']}")
```

### Gi√°m s√°t T·ªïng th·ªÉ S·ª≠ d·ª•ng API key

```python
import json
import time
import datetime

# L·∫•y th·ªëng k√™ s·ª≠ d·ª•ng cho t·∫•t c·∫£ c√°c key
all_key_stats = handler.get_key_stats()

print("\nTh·ªëng k√™ T·ªïng th·ªÉ S·ª≠ d·ª•ng Key:")
print(json.dumps(all_key_stats, indent=2))

# L·∫•y th·ªëng k√™ cho m·ªôt key c·ª• th·ªÉ (v√≠ d·ª•: key th·ª© 2 - index 1)
try:
    key_1_stats = handler.get_key_stats(key_index=1)
    print("\nTh·ªëng k√™ cho Key Index 1:")
    print(json.dumps(key_1_stats, indent=2))
except (IndexError, ValueError) as e:
    print(f"\nKh√¥ng th·ªÉ l·∫•y th·ªëng k√™ cho key index 1: {e}")

# Hi·ªÉn th·ªã th√¥ng tin t·ª´ng key m·ªôt c√°ch d·ªÖ ƒë·ªçc
print("\nChi ti·∫øt t·ª´ng Key:")
for key_idx, stats in all_key_stats.items():
    print(f"  Key {key_idx}:")
    print(f"    S·ªë l·∫ßn s·ª≠ d·ª•ng (trong window): {stats['uses']}")
    last_used_time_str = "Ch∆∞a s·ª≠ d·ª•ng"
    if stats['last_used'] > 0:
        last_used_time_str = datetime.datetime.fromtimestamp(stats['last_used']).strftime('%Y-%m-%d %H:%M:%S')
    print(f"    L·∫ßn cu·ªëi s·ª≠ d·ª•ng: {last_used_time_str}")
    print(f"    S·ªë l·∫ßn th·∫•t b·∫°i li√™n ti·∫øp: {stats['failures']}")
    rate_limited_until_time_str = "Kh√¥ng b·ªã gi·ªõi h·∫°n"
    if stats['rate_limited_until'] > time.time():
        rate_limited_until_time_str = datetime.datetime.fromtimestamp(stats['rate_limited_until']).strftime('%Y-%m-%d %H:%M:%S')
    print(f"    B·ªã gi·ªõi h·∫°n ƒë·∫øn: {rate_limited_until_time_str}")
```

## ‚ö†Ô∏è X·ª≠ l√Ω l·ªói

Th∆∞ vi·ªán ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ x·ª≠ l√Ω l·ªói m·ªôt c√°ch linh ho·∫°t th√¥ng qua c√°c chi·∫øn l∆∞·ª£c v√† qu·∫£n l√Ω key. Tuy nhi√™n, b·∫°n v·∫´n c·∫ßn ki·ªÉm tra k·∫øt qu·∫£ tr·∫£ v·ªÅ.

*   **Ki·ªÉm tra `response['success']` (boolean):** ƒê√¢y l√† ch·ªâ b√°o ch√≠nh v·ªÅ th√†nh c√¥ng hay th·∫•t b·∫°i c·ªßa y√™u c·∫ßu *t·ªïng th·ªÉ*.
*   **Ki·ªÉm tra `response['error']`:** N·∫øu `success` l√† `False`, tr∆∞·ªùng n√†y s·∫Ω ch·ª©a th√¥ng tin l·ªói (v√≠ d·ª•: "Max retries exceeded", "All models failed", "Rate limit exceeded", "Copyright material detected", l·ªói API g·ªëc, l·ªói ph√¢n t√≠ch JSON).
*   **L·ªói Rate Limit (`429`):** `KeyRotationManager` s·∫Ω t·ª± ƒë·ªông x·ª≠ l√Ω l·ªói n√†y b·∫±ng c√°ch ƒë√°nh d·∫•u key l√† b·ªã gi·ªõi h·∫°n v√† ch·ªçn key kh√°c (d·ª±a tr√™n `key_strategy`). N·∫øu t·∫•t c·∫£ c√°c key ƒë·ªÅu b·ªã gi·ªõi h·∫°n, c√°c chi·∫øn l∆∞·ª£c c√≥ th·ªÉ th·∫•t b·∫°i v√† tr·∫£ v·ªÅ l·ªói.
*   **L·ªói B·∫£n quy·ªÅn:** Ph·∫£n h·ªìi b·ªã ch·∫∑n do vi ph·∫°m b·∫£n quy·ªÅn (`finish_reason == 4` trong API response g·ªëc) s·∫Ω ƒë∆∞·ª£c `ResponseHandler` ph√°t hi·ªán v√† tr·∫£ v·ªÅ `success=False` c√πng th√¥ng b√°o l·ªói c·ª• th·ªÉ.
*   **L·ªói Ph√¢n t√≠ch JSON:** Khi y√™u c·∫ßu ƒë·∫ßu ra c√≥ c·∫•u tr√∫c (`response_mime_type="application/json"`), `ResponseHandler` s·∫Ω c·ªë g·∫Øng ph√¢n t√≠ch c√∫ ph√°p ph·∫£n h·ªìi text th√†nh JSON. N·∫øu th·∫•t b·∫°i, `success` s·∫Ω l√† `False` v√† `error` s·∫Ω ch·ªâ ra l·ªói ph√¢n t√≠ch.
*   **L·ªói File API:** C√°c l·ªói li√™n quan ƒë·∫øn t·∫£i l√™n, l·∫•y ho·∫∑c x√≥a file s·∫Ω ƒë∆∞·ª£c tr·∫£ v·ªÅ trong dictionary k·∫øt qu·∫£ c·ªßa c√°c ph∆∞∆°ng th·ª©c `upload_file`, `get_file`, `delete_file`, v.v.
*   **`response['model']`:** Cho bi·∫øt model cu·ªëi c√πng ƒë∆∞·ª£c th·ª≠ (c√≥ th·ªÉ l√† model g√¢y l·ªói ho·∫∑c model fallback).
*   **`response['attempts']`:** Ch·ªâ c√≥ √Ω nghƒ©a v·ªõi chi·∫øn l∆∞·ª£c `RETRY`, cho bi·∫øt s·ªë l·∫ßn ƒë√£ th·ª≠.

```python
# V√≠ d·ª• x·ª≠ l√Ω l·ªói r√µ r√†ng h∆°n
prompt_nguy_hiem = "Prompt vi ph·∫°m ch√≠nh s√°ch n·ªôi dung" # V√≠ d·ª•
response = handler.generate_content(prompt_nguy_hiem)

if response['success']:
    print("Th√†nh c√¥ng:")
    print(response['text'])
else:
    print("="*10 + " L·ªñI X·∫¢Y RA " + "="*10)
    print(f"Th√¥ng b√°o l·ªói: {response['error']}")
    print(f"Model cu·ªëi c√πng th·ª≠: {response['model']}")
    print(f"Index Key cu·ªëi c√πng th·ª≠: {response['api_key_index']}")
    if 'attempts' in response: # Ki·ªÉm tra n·∫øu c√≥ th√¥ng tin attempts
        print(f"S·ªë l·∫ßn th·ª≠ (Retry strategy): {response['attempts']}")

    # X·ª≠ l√Ω c·ª• th·ªÉ d·ª±a tr√™n lo·∫°i l·ªói (v√≠ d·ª•)
    if "Copyright material detected" in response['error']:
        print("-> L·ªói n√†y do n·ªôi dung b·∫£n quy·ªÅn, th·ª≠ l·∫°i v·ªõi prompt kh√°c.")
    elif "Rate limit" in response['error']:
        print("-> L·ªói n√†y do gi·ªõi h·∫°n request, h·ªá th·ªëng s·∫Ω t·ª± chuy·ªÉn key.")
    elif "Failed to parse JSON" in response['error']:
        print("-> L·ªói n√†y do model kh√¥ng tr·∫£ v·ªÅ JSON h·ª£p l·ªá, ki·ªÉm tra l·∫°i prompt ho·∫∑c schema.")
    # ... th√™m c√°c x·ª≠ l√Ω l·ªói kh√°c
```

## ‚öôÔ∏è S·ª≠ d·ª•ng Bi·∫øn M√¥i tr∆∞·ªùng (Ngo√†i file YAML)

B·∫°n c√≥ th·ªÉ c·∫•u h√¨nh m·ªôt s·ªë tham s·ªë ch√≠nh th√¥ng qua bi·∫øn m√¥i tr∆∞·ªùng. Ch√∫ng th∆∞·ªùng **ghi ƒë√®** c√°c gi√° tr·ªã t∆∞∆°ng ·ª©ng trong file YAML (tr·ª´ `api_keys` c√≥ th·ª© t·ª± ∆∞u ti√™n ri√™ng nh∆∞ ƒë√£ n√™u). Proxy c≈©ng c√≥ th·ªÉ b·ªã ghi ƒë√® b·ªüi `HTTP_PROXY`/`HTTPS_PROXY`.

```bash
# API Keys (∆∞u ti√™n cao h∆°n YAML n·∫øu ƒë∆∞·ª£c ƒë·∫∑t)
export GEMINI_API_KEYS="key1,key2,key3"
# export GEMINI_API_KEY="key-cua-ban" # Ch·ªâ d√πng n·∫øu GEMINI_API_KEYS kh√¥ng c√≥

# Proxy (s·∫Ω ghi ƒë√® proxy trong YAML ho·∫∑c proxy_settings)
export HTTP_PROXY="http://proxy.server:port"
export HTTPS_PROXY="http://proxy.server:port"

# C√†i ƒë·∫∑t kh√°c (√≠t d√πng h∆°n, th∆∞·ªùng n√™n ƒë·∫∑t trong YAML ho·∫∑c code)
# export GEMINI_DEFAULT_MODEL="gemini-1.5-pro"
# C√°c c√†i ƒë·∫∑t nh∆∞ rate limit, strategies, retry th∆∞·ªùng ƒë∆∞·ª£c ƒë·∫∑t trong YAML ho·∫∑c khi kh·ªüi t·∫°o handler.
# Bi·∫øn m√¥i tr∆∞·ªùng cho server CLI (n·∫øu kh√¥ng d√πng --args):
# export GEMINI_HOST="127.0.0.1"
# export GEMINI_PORT="9000"
```

**L∆∞u √Ω:** Vi·ªác s·ª≠ d·ª•ng bi·∫øn m√¥i tr∆∞·ªùng ti·ªán l·ª£i cho c·∫•u h√¨nh ƒë∆°n gi·∫£n ho·∫∑c trong m√¥i tr∆∞·ªùng container, nh∆∞ng file YAML cung c·∫•p kh·∫£ nƒÉng c·∫•u h√¨nh chi ti·∫øt v√† c√≥ c·∫•u tr√∫c h∆°n.

## üöÄ V√≠ d·ª• th·ª±c t·∫ø: X√¢y d·ª±ng Chatbot B·ªÅn b·ªâ

V√≠ d·ª• n√†y s·ª≠ d·ª•ng `GeminiHandler` v·ªõi c√°c chi·∫øn l∆∞·ª£c ph√π h·ª£p ƒë·ªÉ t·∫°o ra m·ªôt chatbot c√≥ kh·∫£ nƒÉng x·ª≠ l√Ω l·ªói v√† rate limit t·ªët h∆°n.

```python
from gemini_handler import GeminiHandler, Strategy, KeyRotationStrategy
import sys
import time

# Kh·ªüi t·∫°o handler v·ªõi chi·∫øn l∆∞·ª£c t·ªëi ∆∞u cho chatbot
try:
    chatbot_handler = GeminiHandler(
        config_path="config.yaml", # ƒê·∫£m b·∫£o file n√†y t·ªìn t·∫°i v√† c√≥ key, proxy n·∫øu c·∫ßn
        content_strategy=Strategy.FALLBACK, # ∆Øu ti√™n model t·ªët, fallback n·∫øu l·ªói
        key_strategy=KeyRotationStrategy.SMART_COOLDOWN, # X·ª≠ l√Ω rate limit t·ªët
        system_instruction="B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o th√¢n thi·ªán v√† h·ªØu √≠ch t√™n l√† GemiBot."
    )
    print("GemiBot: ƒê√£ kh·ªüi t·∫°o th√†nh c√¥ng!")
    # In th·ªëng k√™ key ban ƒë·∫ßu (t√πy ch·ªçn)
    # print("Th·ªëng k√™ key ban ƒë·∫ßu:", json.dumps(chatbot_handler.get_key_stats(), indent=2))
except ValueError as e:
    print(f"L·ªói kh·ªüi t·∫°o GeminiHandler: {e}")
    print("Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh API key trong config.yaml ho·∫∑c bi·∫øn m√¥i tr∆∞·ªùng.")
    sys.exit(1) # Tho√°t n·∫øu kh√¥ng c√≥ key
except FileNotFoundError:
    print("L·ªói: Kh√¥ng t√¨m th·∫•y file config.yaml. ƒêang th·ª≠ kh·ªüi t·∫°o kh√¥ng c√≥ config...")
    try:
         chatbot_handler = GeminiHandler(
            # Th·ª≠ n·∫°p key t·ª´ ENV
            content_strategy=Strategy.FALLBACK,
            key_strategy=KeyRotationStrategy.SMART_COOLDOWN,
            system_instruction="B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o th√¢n thi·ªán v√† h·ªØu √≠ch t√™n l√† GemiBot."
         )
         print("GemiBot: ƒê√£ kh·ªüi t·∫°o th√†nh c√¥ng (s·ª≠ d·ª•ng API keys t·ª´ ENV).")
    except ValueError as e_env:
        print(f"L·ªói kh·ªüi t·∫°o GeminiHandler t·ª´ ENV: {e_env}")
        sys.exit(1)


def chat_with_user():
    print("\nGemiBot: Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n? (G√µ 't·∫°m bi·ªát' ƒë·ªÉ tho√°t)")
    conversation_history = [] # L∆∞u tr·ªØ l·ªãch s·ª≠ d∆∞·ªõi d·∫°ng [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]

    while True:
        user_input = input("B·∫°n: ")
        if user_input.lower() in ["t·∫°m bi·ªát", "bye", "exit", "quit"]:
            print("GemiBot: T·∫°m bi·ªát! H·∫πn g·∫∑p l·∫°i!")
            break

        # Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
        conversation_history.append({"role": "user", "content": user_input})

        # T·∫°o prompt t·ª´ l·ªãch s·ª≠ (ƒë∆°n gi·∫£n, ch·ªâ n·ªëi chu·ªói)
        # C√≥ th·ªÉ c·∫£i ti·∫øn ƒë·ªÉ ph√π h·ª£p h∆°n v·ªõi c√°ch model x·ª≠ l√Ω ng·ªØ c·∫£nh
        prompt_parts = []
        if chatbot_handler.system_instruction:
             prompt_parts.append(f"System: {chatbot_handler.system_instruction}")
        for msg in conversation_history:
             role = msg["role"]
             content = msg["content"]
             if role == "user":
                 prompt_parts.append(f"User: {content}")
             elif role == "assistant":
                 prompt_parts.append(f"Assistant: {content}")
        prompt = "\n\n".join(prompt_parts) + "\n\nAssistant:" # Y√™u c·∫ßu model ƒë√≥ng vai Assistant


        # T·∫°o ph·∫£n h·ªìi v·ªõi x·ª≠ l√Ω l·ªói t√≠ch h·ª£p
        # Chi·∫øn l∆∞·ª£c Fallback s·∫Ω t·ª± ƒë·ªông th·ª≠ model kh√°c n·∫øu c·∫ßn
        # model_to_try = "gemini-1.5-pro" # ∆Øu ti√™n model m·∫°nh (n·∫øu c√≥ trong config.models)
        model_to_try = chatbot_handler.config.default_model # S·ª≠ d·ª•ng model m·∫∑c ƒë·ªãnh

        print("GemiBot: (ƒêang suy nghƒ©...)")
        start_time = time.time()
        response = chatbot_handler.generate_content(
            prompt=prompt,
            model_name=model_to_try,
            return_stats=True # L·∫•y th·ªëng k√™ ƒë·ªÉ debug
        )
        end_time = time.time()
        print(f"GemiBot: (Th·ªùi gian ph·∫£n h·ªìi: {end_time - start_time:.2f}s, Key: {response.get('api_key_index', 'N/A')})")


        # Hi·ªÉn th·ªã k·∫øt qu·∫£ ho·∫∑c th√¥ng b√°o l·ªói cu·ªëi c√πng
        if response['success']:
            bot_reply = response['text'].strip()
            print(f"GemiBot: {bot_reply}")
            # Th√™m ph·∫£n h·ªìi c·ªßa bot v√†o l·ªãch s·ª≠
            conversation_history.append({"role": "assistant", "content": bot_reply})
        else:
            error_msg = response['error']
            key_index = response.get('api_key_index', 'N/A')
            model_failed = response.get('model', 'N/A')
            print(f"GemiBot: Xin l·ªói, t√¥i ƒëang g·∫∑p ch√∫t v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t.")
            print(f"  L·ªói: {error_msg}")
            print(f"  (Model: {model_failed}, Key Index: {key_index})")

            # X√≥a l∆∞·ª£t h·ªèi c·ªßa ng∆∞·ªùi d√πng kh·ªèi l·ªãch s·ª≠ n·∫øu bot l·ªói, tr√°nh l·∫∑p l·∫°i
            if conversation_history and conversation_history[-1]["role"] == "user":
                 conversation_history.pop()
            print("GemiBot: Vui l√≤ng th·ª≠ l·∫°i sau gi√¢y l√°t ho·∫∑c ƒë·∫∑t c√¢u h·ªèi kh√°c.")

        # Gi·ªõi h·∫°n l·ªãch s·ª≠ ƒë·ªÉ tr√°nh prompt qu√° d√†i (v√≠ d·ª•: gi·ªØ 10 c·∫∑p tho·∫°i g·∫ßn nh·∫•t)
        MAX_HISTORY_PAIRS = 10
        if len(conversation_history) > MAX_HISTORY_PAIRS * 2:
             conversation_history = conversation_history[-(MAX_HISTORY_PAIRS * 2):]

        # In th·ªëng k√™ key sau m·ªói v√†i l∆∞·ª£t (t√πy ch·ªçn)
        # if len(conversation_history) % 4 == 0: # V√≠ d·ª•: in sau m·ªói 2 l∆∞·ª£t tho·∫°i
        #      print("\n--- Key Stats ---")
        #      print(json.dumps(chatbot_handler.get_key_stats(), indent=2))
        #      print("-----------------\n")


# Ch·∫°y chatbot
if __name__ == "__main__":
    chat_with_user()
```

## üß© C√°c Th√†nh ph·∫ßn Ch√≠nh

*   **`GeminiHandler`:** Class ch√≠nh, l√† ƒëi·ªÉm truy c·∫≠p cho m·ªçi t∆∞∆°ng t√°c. Qu·∫£n l√Ω c·∫•u h√¨nh, key, chi·∫øn l∆∞·ª£c, v√† g·ªçi c√°c API Gemini. K·∫ø th·ª´a t·ª´ `ContentGenerationMixin` v√† `FileOperationsMixin`.
*   **`ContentGenerationMixin`:** Ch·ª©a c√°c ph∆∞∆°ng th·ª©c t·∫°o n·ªôi dung (`generate_content`, `generate_structured_content`, `generate_embeddings`).
*   **`FileOperationsMixin`:** Ch·ª©a c√°c ph∆∞∆°ng th·ª©c li√™n quan ƒë·∫øn file (`upload_file`, `get_file`, `list_files`, `delete_file`, `batch_upload_files`, `generate_content_with_file`, `generate_structured_content_with_file`, `generate_with_local_file`).
*   **`Strategy` (Enum):** ƒê·ªãnh nghƒ©a c√°c chi·∫øn l∆∞·ª£c t·∫°o n·ªôi dung (`ROUND_ROBIN`, `FALLBACK`, `RETRY`).
*   **`KeyRotationStrategy` (Enum):** ƒê·ªãnh nghƒ©a c√°c chi·∫øn l∆∞·ª£c lu√¢n chuy·ªÉn API key (`SEQUENTIAL`, `ROUND_ROBIN`, `LEAST_USED`, `SMART_COOLDOWN`).
*   **`GenerationConfig`:** Dataclass ƒë·ªÉ c·∫•u h√¨nh tham s·ªë model nh∆∞ `temperature`, `top_p`, `max_output_tokens`, `response_mime_type`, `response_schema`.
*   **`EmbeddingConfig`:** Dataclass cho tham s·ªë embedding, bao g·ªìm h·∫±ng s·ªë `task_type`.
*   **`ModelResponse`:** Dataclass chu·∫©n h√≥a cho k·∫øt qu·∫£ g·ªçi API, ch·ª©a `success` (bool), `model` (str), `text` (str), `structured_data` (dict), `embeddings` (list), `error` (str), `time` (float), `api_key_index` (int), `file_info` (dict).
*   **`KeyRotationManager`:** X·ª≠ l√Ω logic ch·ªçn, theo d√µi tr·∫°ng th√°i v√† lu√¢n chuy·ªÉn API key d·ª±a tr√™n chi·∫øn l∆∞·ª£c v√† rate limit.
*   **`FileHandler`:** L·ªõp c·∫•p th·∫•p h∆°n chuy√™n x·ª≠ l√Ω t∆∞∆°ng t√°c v·ªõi Gemini File API (upload, get, list, delete). ƒê∆∞·ª£c `GeminiHandler` s·ª≠ d·ª•ng n·ªôi b·ªô.
*   **`EmbeddingHandler`:** L·ªõp chuy√™n x·ª≠ l√Ω vi·ªác g·ªçi API embedding, s·ª≠ d·ª•ng `KeyRotationManager`.
*   **`ResponseHandler`:** X·ª≠ l√Ω v√† chu·∫©n h√≥a ph·∫£n h·ªìi th√¥ t·ª´ API Gemini, bao g·ªìm ki·ªÉm tra l·ªói b·∫£n quy·ªÅn v√† ph√¢n t√≠ch JSON.
*   **`strategies.py`:** Ch·ª©a c√°c class tri·ªÉn khai `ContentStrategy` (RoundRobinStrategy, FallbackStrategy, RetryStrategy).
*   **`config.py` (`ConfigLoader`):** Ti·ªán √≠ch n·∫°p API key v√† proxy t·ª´ nhi·ªÅu ngu·ªìn cho `GeminiHandler`.
*   **`proxy.py` (`ProxyManager`):** Qu·∫£n l√Ω c·∫•u h√¨nh proxy cho c√°c request HTTP.
*   **`server.py` (`GeminiServer`):** Implement server FastAPI t∆∞∆°ng th√≠ch OpenAI.
*   **`cli.py`:** Giao di·ªán d√≤ng l·ªánh ƒë·ªÉ kh·ªüi ch·∫°y `GeminiServer`.
*   **`litellm_integration.py` (`LiteLLMGeminiAdapter`):** Adapter ƒë·ªÉ t√≠ch h·ª£p v·ªõi LiteLLM.
*   **`config_loader.py` (`ServerConfig`):** (√çt d√πng tr·ª±c ti·∫øp) L·ªõp c·∫•u h√¨nh ri√™ng cho server, nh∆∞ng `cli.py` hi·ªán ƒëang ƒë·ªçc YAML tr·ª±c ti·∫øp.

## üìÑ Gi·∫•y ph√©p

D·ª± √°n n√†y ƒë∆∞·ª£c ph√°t h√†nh theo Gi·∫•y ph√©p MIT - xem file `LICENSE` ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt. (B·∫°n n√™n t·∫°o file `LICENSE` ch·ª©a n·ªôi dung gi·∫•y ph√©p MIT n·∫øu ch∆∞a c√≥).

## ü§ù ƒê√≥ng g√≥p

M·ªçi ƒë√≥ng g√≥p ƒë·ªÅu ƒë∆∞·ª£c ch√†o ƒë√≥n! Vui l√≤ng t·∫°o Pull Request ho·∫∑c m·ªü Issue n·∫øu b·∫°n c√≥ √Ω t∆∞·ªüng c·∫£i ti·∫øn ho·∫∑c ph√°t hi·ªán l·ªói.

Quy tr√¨nh ƒë√≥ng g√≥p ƒë·ªÅ xu·∫•t:
1.  Fork kho l∆∞u tr·ªØ.
2.  T·∫°o m·ªôt nh√°nh m·ªõi (`git checkout -b feature/ten-tinh-nang-cua-ban`).
3.  Th·ª±c hi·ªán c√°c thay ƒë·ªïi c·ªßa b·∫°n.
4.  Th√™m unit test cho c√°c thay ƒë·ªïi (n·∫øu c√≥ th·ªÉ).
5.  ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c test ƒë·ªÅu pass.
6.  Format code c·ªßa b·∫°n (v√≠ d·ª•: d√πng Black, Flake8).
7.  Commit c√°c thay ƒë·ªïi (`git commit -m 'Them tinh nang X'`).
8.  Push l√™n nh√°nh (`git push origin feature/ten-tinh-nang-cua-ban`).
9.  M·ªü m·ªôt Pull Request.
